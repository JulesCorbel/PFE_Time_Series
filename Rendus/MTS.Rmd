---
title: "Package MTS"
author: "Jules CORBEL & Paul GUILLOTTE"
date: "05/02/2019"
output: pdf_document
---

```{r setup, include=FALSE}
require(tseries)
require(forecast)
require(corrplot)
require(fUnitRoots)
require(MTS)
require(portes)

#Code permettant la mise en place de la représentation visuelle de la matrice des corrélations
cor.mtest <- function(mat, conf.level = 0.95){
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  diag(lowCI.mat) <- diag(uppCI.mat) <- 1
  for(i in 1:(n-1)){
    for(j in (i+1):n){
      tmp <- cor.test(mat[,i], mat[,j], conf.level = conf.level)
      p.mat[i,j] <- p.mat[j,i] <- tmp$p.value
      lowCI.mat[i,j] <- lowCI.mat[j,i] <- tmp$conf.int[1]
      uppCI.mat[i,j] <- uppCI.mat[j,i] <- tmp$conf.int[2]
    }
  }
  return(list(p.mat, lowCI.mat, uppCI.mat))
}

EQM<-function(serie, prediction){
  return(sum((serie - prediction)^2)/length(serie))
}
```

Nous nous intéresserons dans ce document à la mise en place de modèles VAR à l'aide du package **MTS** afin de prédire la masse salariale trimestrielle. Un modèle VAR, pour  Vecteur AutoRégressif, a pour objectif de capturer les interdépendances entre les différentes séries temporelles à notre disposition. Ainsi, chaque variable est expliquée par ses propres valeurs passées ainsi que par les valeurs passées des autres variables du modèle.

# Visualisation des séries

Même contenu que pour le package vars

```{r, include=FALSE}
trim <- read.csv("~/PFE_Time_Series/Data/Data_Trim.csv", sep=";", dec=",")
corrplot(cor(trim[1:109,-1]), method = "number", type="lower",
         p.mat=cor.mtest(trim[1:109,-1], 0.95)[[1]], insig="pch",
         col=colorRampPalette(c("blue", "light blue", "red"))(50), title = "
         Corrélations entre les variables trimestrielles")

  MSE <- ts(trim$MSE, start = 1990, end = c(2017, 2), frequency=4)
  plot(MSE, main="Evolution de la masse salariale trimestrielle")
  par(mfrow=c(1,2))
  acf(MSE, main="Auto-corrélation de la
      masse salariale trimestrielle", lag.max=20)
  pacf(MSE, main="Autocorrélation partielle
       de la masse trimestrielle", lag.max=20)
  kpss.test(MSE)

  PIB <- ts(trim$PIB, start = 1990, end = c(2017, 1), frequency=4)
  plot(PIB, main="Evolution du PIB trimestriel")
  par(mfrow=c(1,2))
  acf(PIB, main="Auto-corrélation 
      du PIB trimestriel", lag.max=20)
  pacf(PIB, main="Autocorrélation partielle
       du PIB trimestriel", lag.max=20)
  par(mfrow=c(1,1))
  kpss.test(PIB)

  SMIC <- ts(trim$SMIC, start = c(1990,1), end = c(2017, 4), frequency = 4)
  plot(SMIC, main="Evolution du SMIC trimestriel")
  par(mfrow=c(1,2))
  acf(SMIC, main="Auto-corrélation du
      SMIC trimestriel", lag.max=20)
  pacf(SMIC, main="Autocorrélation partielle
       du SMIC trimestriel", lag.max=20)
  par(mfrow=c(1,1))
  kpss.test(SMIC)
  
  TCHOF <- ts(trim$TCHOF, start = c(1990,1), end = c(2017, 4), frequency = 4)
  plot(TCHOF, main="Evolution du TCHOF trimestriel")
  par(mfrow=c(1,2))
  acf(TCHOF, main="Auto-corrélation du
      TCHOF trimestriel", lag.max=20)
  pacf(TCHOF, main="Autocorrélation partielle
       du TCHOF trimestriel", lag.max=20)
  par(mfrow=c(1,1))
  kpss.test(TCHOF)
```

# Transformation des séries

Même contenu que pour le package vars

```{r, include=FALSE}
  plot(decompose(MSE, "multiplicative"))
  MSESta <- na.omit(decompose(MSE, "multiplicative")$random)
  MSETrendTest<-window(decompose(MSE, "multiplicative")$trend, start=2016, end=c(2016,4))
  MSESeasonalTest<-window(decompose(MSE, "multiplicative")$seasonal, start=2016, end=c(2016,4))
  par(mfrow=c(1,2))
  acf(MSESta, main="Auto-Corrélation de la Masse
      salariale trimestrielle stationnarisée")
  pacf(MSESta, main="Auto-Corrélation partielle de la Masse
       salariale trimestrielle stationnarisée")
  par(mfrow=c(1,1))
  kpss.test(MSESta)
  plot(MSESta, main="Masse salariale trimestrielle stationnarisée")
  MSEStaTrain <- window(MSESta, end=c(2015,4))
  MSEStaTest <- window(MSESta, start=2016)
  MSETrain <- window(MSE, end=c(2015,4))
  MSETest <- window(MSE, start=2016)

  PIBSta <- na.omit(decompose(PIB, "multiplicative")$random)
  par(mfrow=c(1,2))
  acf(PIBSta, main="Auto-Corrélation du PIB
      trimestrielle stationnarisée")
  pacf(PIBSta, main="Auto-Corrélation partielle du PIB
      trimestrielle stationnarisée")
  par(mfrow=c(1,1))
  kpss.test(PIBSta)
  plot(PIBSta, main="PIB trimestriel stationnarisé")
  PIBStaTrain <- window(PIBSta, end=c(2015,4))
  PIBStaTest <- window(PIBSta, start=2016)
  PIBTrain <- window(PIB, end=c(2015,4))
  PIBTest <- window(PIB, start=2016)

  SMICSta <- na.omit(decompose(SMIC)$random)
  par(mfrow=c(1,2))
  acf(SMICSta, main="Auto-Corrélation du SMIC
      trimestrielle stationnarisée")
  pacf(SMICSta, main="Auto-Corrélation partielle du SMIC
      trimestrielle stationnarisée")
  par(mfrow=c(1,1))
  kpss.test(SMICSta)
  plot(SMICSta, main="SMIC trimestriel stationnarisé")
  SMICStaTrain <- window(SMICSta, end=c(2015,4))
  SMICStaTest <- window(SMICSta, start=2016)
  SMICTrain <- window(SMIC, end=c(2015,4))
  SMICTest <- window(SMIC, start=2016)

  TCHOFSta <- na.omit(decompose(TCHOF)$random)
  par(mfrow=c(1,2))
  acf(TCHOFSta, main="Auto-Corrélation du Taux de
      chômage des femmes
      trimestrielle stationnarisée")
  pacf(TCHOFSta, main="Auto-Corrélation partielle
      du Taux de chômage des femmes
      trimestrielle stationnarisée")
  par(mfrow=c(1,1))
  kpss.test(TCHOFSta)
  plot(TCHOFSta, main="Taux de chômage trimestriel des femmes stationnarisé")
  TCHOFStaTrain <- window(TCHOFSta, end=c(2015,4))
  TCHOFStaTest <- window(TCHOFSta, start=2016)
  TCHOFTrain <- window(TCHOF, end=c(2015,4))
  TCHOFTest <- window(TCHOF, start=2016)
```

# Calcul de l'ordre p

Afin de mettre en place une modélisation VAR, nous devons dans un premier temps nous intéresser à l'ordre p du modèle VAR. L'ordre p correspond à l'ordre de l'opérateur de retard, c'est-à-dire le nombre de valeurs du passé qui ont un impact sur la valeur à un instant défini. Dans le package **MTS**, la fonction utilisée est VARorder, qui comme VARselect utilise les critères d'AIC, BIC et HQ afin de déterminer l'ordre du processus. Toutefois, le critère FPE n'est pas présent, ce qui nous conforte dans notre idée qu'il n'est pas très utile à notre étude. Les valeurs des différents indicateurs nous font retenir un ordre p=3.

```{r}
selec <- VARorder(cbind(MSEStaTrain, PIBStaTrain, SMICStaTrain, TCHOFStaTrain), maxp=10)
```


# Estimation du modèle

Dans le package **MTS**, la fonction utilisée pour construire des modèles VAR est *VAR,* qui prend en entrée la série temporelle multivariée et l'ordre du processus. On affiche ci-dessous les résultats renvoyés par la fonction sur le modèle
```{r}
modele<-VAR(cbind(MSEStaTrain, PIBStaTrain, SMICStaTrain, TCHOFStaTrain), p=3, output=F)
print("Coefficients du modèle")
coeff<-modele$coef[2:5,]
colnames(coeff)<-rownames(coeff)<-c("MSE", "PIB", "SMIC", "TCHOF")
coeff
print("Erreurs standard des coefficients")
se<-modele$secoef[2:5,]
colnames(se)<-rownames(se)<-c("MSE", "PIB", "SMIC", "TCHOF")
se
```

```{r}
matrix(data=c(modele$aic, modele$bic, modele$hq), nrow=1, byrow=T, dimnames=list(NULL, c("AIC", "BIC", "HQ")))
```
Afin de vérifier que les résidus du modèle ne présentent ni d'auto-corrélation (corrélation dans une série entre deux temps différents), ni de corrélation croisée (corrélation entre deux séries différentes).

```{r}
LjungBox(modele$residuals, 1:10)
```

L'hypothèse nulle d'indépendance des résidus est conservée, ce qui nous permet de valider notre modèle.

# Prévisions

Maintenant que nous avons estimé l'ordre des différents modèle VAR, et que nous avons explicité l'estimation des modèles, nous cherchons désormais à trouver celui dont les prédictions sont les plus proches de la réalité.

Après avoir comparé tous les modèles possibles (7 : 3 modèles avec deux variables, 3 modèles avec trois variables et un modèle avec les quatre variables), nous nous apercevons que le meilleur en terme de prédictions est le modèle prenant en compte le SMIC et le PIB, avec un ordre égal à 4.

```{r, results="hide"}
#SMIC
VARorder(cbind(MSEStaTrain, SMICStaTrain, PIBStaTrain), maxp=10)
modele<-VAR(cbind(MSEStaTrain, SMICStaTrain, PIBStaTrain), p=4)
pred <- VARpred(modele, 4)
```

```{r}
plot(window(MSETest, end=c(2016,4)), main="Différences entre les véritables
     valeurs de 2016 et les prédictions du modèle pour la masse salariale")
#Reconstruction de la variable stationnaire
recon <- ts(pred$pred[,1], start=2016, frequency=4) * MSETrendTest * MSESeasonalTest
lines(recon, col = "red")
legend('bottomleft', legend = c('Série MSE', 'Prévisions du modèle'),
       col=c('black', 'red'), lty=1, cex=0.8)
```

Nous nous intéressons donc à l'erreur quadratique moyenne de cette prévision, qui est inférieure à celle obtenue pour le meilleur modèle effectué avec le package **vars**.

```{r}
EQM(MSETest, recon)
```