---
title: "Rapport final"
author: "Paul GUILLOTTE & Jules CORBEL"
date: "01/02/2019"
fontsize : 11pt

output: 
  pdf_document:
    keep_tex: true
    toc: yes
    number_sections: yes 
    fig_caption: yes
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
bibliography : bibliography.bib
nocite: '@*'
---
```{r setup, include=FALSE}
require(tseries)
require(knitr)
require(forecast)
require(corrplot)
require(fUnitRoots)
require(vars)

#Code permettant la mise en place de la représentation visuelle de la matrice des corrélations
cor.mtest <- function(mat, conf.level = 0.95){
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  diag(lowCI.mat) <- diag(uppCI.mat) <- 1
  for(i in 1:(n-1)){
    for(j in (i+1):n){
      tmp <- cor.test(mat[,i], mat[,j], conf.level = conf.level)
      p.mat[i,j] <- p.mat[j,i] <- tmp$p.value
      lowCI.mat[i,j] <- lowCI.mat[j,i] <- tmp$conf.int[1]
      uppCI.mat[i,j] <- uppCI.mat[j,i] <- tmp$conf.int[2]
    }
  }
  return(list(p.mat, lowCI.mat, uppCI.mat))
}

EQM<-function(serie, prediction){
  return(sum((serie - prediction)^2)/length(serie))
}

stabilityMTS<-function(modele){
  k<-ncol(modele$data)
  p<-modele$order
  A <- matrix(0,nrow=p*k, ncol=p*k)
  deb<-nrow(A)-k+1
  for(i in seq(1,(nrow(A)-2*k+1),k)){
    A[i:(i+k-1),(i+k):(i+k*2-1)] = diag(k)
  }
  j = ncol(A)
  for(i in seq(1,deb,k)){
    A[deb:nrow(A),(j-k+1):j] = t(modele$coef[(i+1):(i+k),])
    j = j-k
  }
  vp<-eigen(A)$values
  print(Mod(vp))
  plot(seq(1,nrow(A)), Mod(vp), xlab="",
       ylab="Valeurs propres", ylim=c(0,1.5))
  abline(h=1, col="red")
}

#trim <- read.csv("~/PFE_Time_Series/Data/Data_Trim.csv", sep=";", dec=",")
trim <- read.csv("~/Cygwin/app/home/Jules/PFE_Time_Series/Data/Data_Trim.csv", sep=";", dec=",")
```

#Introduction {-}
Dans le cadre de la formation Génie Informatique et Statistique (GIS), l’un des modules qui nous est proposé est la réalisation d’un projet de fin d’études (PFE) en lien avec une entreprise ou un laboratoire. Notre PFE s’effectue en lien avec l’Institut des Retraites Complémentaires des Employés de Maison (IRCEM) et a pour but de construire des modèles statistiques afin de prédire la masse salariale du secteur d’activité des services à la personne pour les années à venir. 

L’IRCEM a été créée en 1973. Cet organisme à but non lucratif s’occupe de la protection sociale des employés du secteur du service à la personne. Dans ce but, il doit verser des compléments de salaire aux employés à l’aide à la personne. Il effectue alors régulièrement des prévisions de la masse salariale de ce secteur d’activités, afin d’estimer l’argent  qu’il devra verser.

Notre mission pour ce projet est donc de modéliser cette masse salariale et d’effectuer des prévisions pour les années 2018 et 2019, qui seront effectuées en utilisant différentes méthodes de prédiction. La première partie du projet nous a vus nous concentrer sur des méthodes de prédiction univariées, tel que le lissage exponentiel et des modélisations basées sur des processus ARMA. Nous avions également commencé à modéliser la masse salariale à l'aide des variables auxiliaires. Ici, nous présentons nos travaux sur les modèles vectoriels (modèles VAR plus des essais sur les modèles VARMA). L’intégralité du projet s’est effectuée sur le logiciel R.

\newpage
#Description des jeux de données

Les données que nous a fourni l’IRCEM sont comprises dans deux jeux de données représentant deux ensembles de variables distincts : l’un contient des variables annuelles et l’autre des variables trimestrielles, dans les deux cas à partir de 1990. Afin d’aider à la prédiction des valeurs de la masse salariale, nous devrons nous appuyer sur plusieurs variables auxiliaires. Pour les données annuelles, nous disposons de 4 variables : le SMIC horaire brut, le PIB, le taux de chômage et le montant de l’Allocation pour la Garde des Enfants à Domicile. La masse salariale annuelle est connue jusqu’en 2017, et on possède les informations sur les autres variables jusqu’à 2019. En ce qui concerne le modèle trimestriel, nous disposons de 3 variables : le SMIC, le PIB et le taux de chômage des femmes. La masse salariale trimestrielle est connue jusqu’au 2e trimestre de 2017. Le PIB trimestriel est lui connu jusqu’au 1er trimestre 2017. Pour les deux autres variables, les informations que nous possédons vont jusqu’au dernier trimestre de 2017. Le faible nombre de données (surtout pour les variables annuelles) a cependant été un obstacle. En effet, dans le jeu annuel, il n’y a 28 années, ce qui représente peu de valeurs pour créer des modèles pertinents. Nous nous sommes donc concentrés uniquement sur le jeu de données trimestriel.

\newpage
#Analyse descriptive des séries

##Rappel sur la stationnarité du second ordre

Avant de commencer à analyser les séries, nous rappelons des bases sur des notions dont nous aurons besoin par la suite.

Dans de nombreux modèles de séries temporelles, la série en entrée doit satisfaire une hypothèse de stationnarité. Les conditions de la stationnarité du second ordre sont les suivantes :

$E[y_{t}]=\mu \forall t=1...T$

$Var[y_{t}]=\sigma ^{2}\neq \infty \forall t=1...t$

$Cov[y_{i},Z_{i-k}]=f(k) \forall i=1...t, \forall k=1...t$

Nous nous intéressons dans ce rapport aux différentes séries trimestrielles à notre disposition. Dans un premier temps, nous visualiserons chacune de séries. Nous vérifierons ensuite les corrélations entre les variables deux à deux afin de nous faire une idée du lien qu'il existe entre les variables.

##Masse salariale \label{MSE}

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig1} Evolution trimestrielle de la masse salariale", echo=F}
  MSE <- ts(trim$MSE, start = 1990, end = c(2017, 2), frequency=4)
  plot(MSE, xaxt="n", cex.main=0.9)
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", 
                                             "2010Q1", "2015Q1"))
```

La masse salariale trimestrielle, représentée en Figure \ref{fig1} possède une composante de tendance de 1990 à 2010. La série tend par la suite à stagner. Nous remarquons également une saisonnalité sur cette série, qui est de plus en plus marquée à mesure que le temps passe. 

```{r, fig.height=3, fig.cap="\\label{fig2} Fonctions d'autocorrélation de la masse salariale trimestrielle", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(MSE, main="Auto-corrélation de la
      masse salariale trimestrielle", lag.max=20)
  pacf(MSE, main="Autocorrélation partielle
       de la masse salariale trimestrielle", lag.max=20)
  kpss.test(MSE)
  adf.test(MSE)
```

Comme la série comporte une tendance et une saisonnalité, elle ne correspond pas aux deux premières conditions de la stationnarité du second ordre, soit que la série possède une moyenne et un écart-type constants. Cela est confirmé par la Figure \ref{fig2}, qui nous montre la fonction ACF qui décroît régulièrement. Nous effectuons également un test de KPSS (test de stationnarité) servant à vérifier si la série est stationnaire ou non (sous l'hypothèse $H_{0}$ la série est stationnaire, et sous l'hypothèse $H_{1}$ elle ne l'est pas). La série est dite stationnaire si ses propriétés statistiques (espérance, variance et auto-corrélation) sont fixes au cours du temps. La p-value est de 0.01 ce qui nous confirme que la série n'est pas stationnaire avec un risque de première espèce de 5%. Nous mettons également en place un test de racines unitaires, le test de Dickey Fuller augmenté. Son hypothèse nulle est que la série a été générée par un processus présentant une racine unitaire, et donc que la série n'est pas stationnaire. Ici, avec un risque de première espèce à 5%, on conserve l'hypothèse nulle et on conclut, à l'aide des deux tests effectués, que la série n'est pas stationnaire. 

##PIB  \label{PIB}

La Figure \ref{fig3} nous montre l'évolution trimestriel du PIB qui, comme pour la masse salariale possède une tendance. Cependant, elle ne semble pas posséder de saisonnalité. Cette série ne semble donc pas non plus stationnaire. Nous effectuons à nouveau un test de KPSS. La p-value est de 0.01 ce qui nous confirme que la série n'est pas stationnaire avec un risque de première espèce de 5%. Même conclusion au regard du test augmenté de Dickey Fuller.

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig3} Evolution trimestrielle du PIB", echo=F}
  PIB <- ts(trim$PIB, start = 1990, end = c(2017, 1), frequency=4)
  plot(PIB, xaxt="n", cex.main=0.9)
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

```{r, fig.height=3, fig.cap="\\label{fig4} ACF et PACF du PIB trimestriel", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(PIB, main="Auto-corrélation 
      du PIB trimestriel", lag.max=40)
  pacf(PIB, main="Autocorrélation partielle
       du PIB trimestriel", lag.max=40)
  par(mfrow=c(1,1))
  kpss.test(PIB)
  adf.test(PIB)
```

##SMIC

Au regard de la Figure \ref{fig5}, on s'aperçoit qu'il y a bien une tendance. Pour la saisonnalité, il est plus difficile de savoir s'il en existe une ou pas, puisque la série semble augmenter seulement à certains temps. Les tests de KPSS et de Dickey Fuller augmenté nous confirment que la série n'est pas stationnaire.
```{r, fig.width=4, fig.height=3.5, fig.align='center', fig.cap="\\label{fig5} Evolution trimestrielle du SMIC", echo=F}
  SMIC <- ts(trim$SMIC, start = c(1990,1), end = c(2017, 4), frequency = 4)
  plot(SMIC, main="", xaxt="n", cex.main=0.9)
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

```{r, fig.height=3, fig.cap="\\label{fig6} ACF et PACF du SMIC trimestriel", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(SMIC, main="Auto-corrélation du
      SMIC trimestriel", lag.max=20)
  pacf(SMIC, main="Autocorrélation partielle
       du SMIC trimestriel", lag.max=20)
  par(mfrow=c(1,1))
  kpss.test(SMIC)
  adf.test(SMIC)
```

##Taux de chômage des femmes \label{TCHOF}

Pour cette dernière série (Figure \ref{fig7}) qui représente le taux de chômage trimestriel des femmes, il ne semble pas y avoir de saisonnalité. On remarque cependant qu'il y a bien une tendance, au regard de la Figure \ref{fig8}. En regardant la série de plus près, on s'aperçoit que la tendance semble être "par morceaux" : d'abord une hausse de 1990 à 1996, puis elle décroît jusqu'en 2002, avant d'augmenter à nouveau jusqu'en 2007, de chuter jusqu'en 2010. Si la série ne possède pas une tendance uniforme sur toute la durée étudiée, elle semble donc bien posséder une tendance par morceaux. Les tests KPSS et de Dickey Fuller augmenté nous confirment que la série n'est pas stationnaire, avec un risque de première espèce de 5%.
```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig7} Evolution trimestrielle du taux de chômage des femmes", echo=F}
  TCHOF <- ts(trim$TCHOF, start = c(1990,1), end = c(2017, 4), frequency = 4)
  plot(TCHOF, xaxt="n", cex.main=0.9)
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```
```{r, fig.height=3, fig.cap="\\label{fig8} ACF et PACF du taux de chômage des femmes trimestriel", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(TCHOF, main="Auto-corrélation du taux de
      chômage des femmes trimestriel", lag.max=20)
  pacf(TCHOF, main="Autocorrélation partielle du
       taux de chômage des femmes trimestriel", lag.max=20)
  par(mfrow=c(1,1))
  kpss.test(TCHOF)
  adf.test(TCHOF)
```

##Calcul des corrélations

```{r, fig.width=4, fig.height=3, fig.cap="\\label{fig9} Corrélations entre les variables trimestrielles", echo=F}
corrplot(cor(trim[1:109,-1]), method = "number", type="lower",
         p.mat=cor.mtest(trim[1:109,-1], 0.95)[[1]], insig="pch",
         col=colorRampPalette(c("blue", "light blue", "red"))(50))
corr <- cor.mtest(trim[1:109,-1], 0.95)[[1]]
rownames(corr) <- c("MSE","PIB","SMIC","TCHOF")
colnames(corr) <- c("MSE","PIB","SMIC","TCHOF")
corr
```

Nous affichons la matrice des corrélations des différentes variables en Figure \ref{fig9}. On se rend compte que le taux de chômage des femmes est corrélé négativement avec toutes les autres variables. Les variables PIB, masse salariale et SMIC sont extrêmement liées entre elles. En regardant le tableau des p-values associées au test de Student (H0 : La corrélation entre les deux variables est nulle), on s'aperçoit que toutes les variables prises deux à deux présentes une corrélation.

##Découpage des séries

Pour chacune des séries, nous allons créer un échantillon d'apprentissage, qui nous permettra de construire les différents modèles, ainsi qu'un échantillon de test, qui nous permettra de comparer les prédictions des modèles construits avec des vraies valeurs. L'échantillon d'apprentissage sera composé de toutes les valeurs du premier trimestre 1990 jusqu'au 4e trimestre 2015, tandis que celui de test comprendra toutes les valeurs à partir du 1er trimestre 2016.

```{r, echo=F}
MSETrain <- window(MSE, start=1990, end=c(2015,4))
MSETest <- window(MSE, start=2016, end=c(2017,2))
PIBTrain <- window(PIB, start=1990, end=c(2015,4))
PIBTest <- window(PIB, start=2016, end=c(2017,1))
SMICTrain <- window(SMIC, start=1990, end=c(2015,4))
SMICTest <- window(SMIC, start=2016, end=c(2017,2))
TCHOFTrain <- window(TCHOF, start=1990, end=c(2015,4))
TCHOFTest <- window(TCHOF, start=2016, end=c(2017,2))
```

##Estimation de la valeur manquante du PIB

Contrairement aux autres variables, nous n'avons à notre disposition pour le PIB que les valeurs jusqu'au premier trimestre de 2017. Ceci nous impose de négliger la dernière valeur de toutes les autres séries pour que toutes les variables soient étudiées sur la même période. Pour éviter ce problème, nous décidons d'estimer la variable du PIB pour le 2e trimestre de 2017. Afin de faire cela, nous allons utiliser la valeur estimée par un modèle SARIMA correspondant à la variable PIB, étant donné que c'est celui qui donnait les meilleures prédictions (voir \ref{Annexe1}).

```{r, echo=F}
PredARIMAPIB<- forecast(auto.arima(PIBTrain), h=6)
new.value <- PredARIMAPIB$mean[6]
PIBTest<-ts(c(PredARIMAPIB$mean, new.value), start = 2016, end = c(2017, 2), frequency=4)
```

\newpage
# Modélisation vectorielle

Dans la première partie du projet, nous avons modélisé les différentes séries séparément, à l'aide de modèles de lissage exponentiel ou des processus ARMA, dont les résultats sont présents en Annexe \ref{Annexe1}. Nous avons ensuite effectué d'autres modèles ARMA sur la masse salariale en uilisant les autres variables pour l'expliquer. Ces modèles sont présents en Annexe \ref{Annexe2}. Cependant, ce type de modélisation ne nous donne pas de résultats plus performants en terme de prédictions.

Pendant la deuxième partie du projet, nous nous sommes donc attachés à utiliser d'autres méthodes de modélisation. Nous nous sommes concentrés sur les modèles de type vectoriels, qui permettent donc de prédire plusieurs séries temporelles simultanément. La plus grande partie de nos travaux portent sur des modèles Vector Auto-Regressive (VAR) plus quelques tests avec l'ajout d'une partie Moving Average (MA) ce qui nous donne des modèles VARMA.

## Définition des modèles

### Ecriture

Un modèle VAR s'écrit sous la forme suivante : 

  $y_t = \sum_{i = 1}^{p} {A_iy_{t-i}} + u_t$
  
$A_i$ représentent les matrices de coefficients du modèle pour un ordre $i$ et $u_t$ une matrice K-dimensionnelle composée des résidus du modèle (indépendants et identiquement distribués). Enfin, $p$ correspond à l'ordre du modèle, qui est en fait le nombre de valeurs du passé prises en compte pour calculer la valeur présente.

### Hypothèses

#### Stabilité du modèle

Pour que le modèle soit valide, nous devons vérifier que l'hypothèse de stabilité est bien respecté. Cette dernière permet d'assurer que les différentes séries du modèle sont stationnaires. Pour vérifier si un processus VAR est stable, nous devons calculer les valeurs propres de la matrice des coefficients suivantes : 

$$A = \begin{bmatrix}
A_1 & A_2 & \cdots & A_{p-1} & A_p \\
I & 0 & \cdots & 0 & 0 \\
0 & I & \cdots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \cdots & I & 0 
\end{bmatrix}$$

Si les modules des valeurs propres de A sont inférieures à 1, alors le processus VAR est stable.

#### Hypothèses sur les résidus

Pour que le modèle soit valide, certaines conditions sur les résidus doivent également être validées. Il s'agit des suivantes :

* Homoscédasticité
* Normalité
* Absence d'auto-corrélations et de corrélations croisées

## Transformation des séries

Nous allons maintenant transformer les séries pour les rendre stationnaires, afin de pouvoir appliquer les modèles VAR ensuite. Afin de stationnariser les séries, nous utiliserons la fonction *decompose* qui permet de découper la série en trois : la tendance, la saisonnalité et les résidus, afin de pouvoir ensuite travailler avec les résidus. Nous ne stationnariserons que les échantillons d'apprentissage.

### Masse salariale

```{r, fig.width=4.5, fig.height=4, fig.cap="\\label{fig10} Décomposition de la masse salariale", echo=F}
par(cex.main=0.8)
  plot(decompose(MSETrain, "multiplicative"))
  MSESta <- na.omit(decompose(MSETrain, "multiplicative")$random)
  MSETrend<-window(decompose(MSETrain, "multiplicative")$trend)
  MSESeasonal<-window(decompose(MSETrain, "multiplicative")$seasonal)
```

Nous nous intéressons aux ACF, PACF (visibles en Figure \ref{fig11}) et test de KPSS afin de vérifier si les résidus obtenus à l'aide de la fonction *decompose* sont stationnaires. Bien que l'ACF et la PACF nous mettent en garde d'une possible non stationnarité de la série, la p-value des tests de KPSS et Dickey Fuller augmenté nous amène à confirmer que notre série est désormais stationnarisée (avec un seuil de confiance à 5% pour les deux tests effectués).

```{r, fig.height=2.5, fig.cap="\\label{fig11} Fonctions d'autocorrélation de la masse salariale stationnarisée", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(MSESta, main="ACF de la masse
      salariale stationnarisée")
  pacf(MSESta, main="PACF de la masse
       salariale stationnarisée")
  par(mfrow=c(1,1))
  kpss.test(MSESta)
  adf.test(MSESta)
  MSETrendTest <- window(forecast(na.omit(MSETrend), h=8)$mean, start=2016)
  MSESeasonalTest<-ts(c(MSESeasonal[103:104], rep(MSESeasonal[1:4],3)), start=c(2015,3),frequency=4)
```
```{r, fig.width=3.5, fig.height=3, fig.cap="\\label{fig12} Masse salariale trimestrielle stationnarisée", echo=F}
  plot(MSESta, xaxt="n")
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

\newpage
### PIB

```{r, fig.width=5, fig.height=4.5, fig.cap="\\label{fig13} PIB trimestriel stationnarisé", echo=F}
  PIBSta <- na.omit(decompose(PIBTrain, "multiplicative")$random)
  plot(PIBSta, main="PIB trimestriel stationnarisé", xaxt="n")
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

```{r, fig.height=2.5, fig.cap="\\label{fig14} Fonctions d'autocorrélation du PIB stationnarisé", echo=F}
  par(mfrow=c(1,2))
  acf(PIBSta, main="Auto-Corrélation du PIB
      trimestriel stationnarisé")
  pacf(PIBSta, main="Auto-Corrélation partielle du PIB
      trimestriel stationnarisé")
  par(mfrow=c(1,1))
```

```{r, echo=F}
  kpss.test(PIBSta)
  adf.test(PIBSta)
```


Nous nous intéressons aux ACF, PACF, test de KPSS et test de Dickey Fuller augmenté (Figure \ref{fig12}) afin de vérifier si les résidus obtenus à l'aide de la fonction *decompose* sont stationnaires. Au regard de ces différentes informations, nous pouvons conclure à la stationnarité des résidus.

### SMIC

```{r, fig.width=3.5, fig.height=3, fig.cap="\\label{fig15} SMIC trimestriel stationnarisé", echo=F}
  SMICSta <- na.omit(decompose(SMICTrain)$random)
  plot(SMICSta, main="SMIC trimestriel stationnarisé", xaxt="n")
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

Comme pour la masse salariale, les ACF et PACF de la Figure \ref{fig16} semblent montrer que la série résiduelle pourrait ne pas être stationnaire. Cependant le test de KPSS ainsi que le test de Dickey Fuller augmenté nous permettent de conclure à la stationnarité des résidus.

```{r, fig.height=2.5, fig.cap="\\label{fig16} Fonctions d'autocorrélation du SMIC stationnarisé", echo=F}
  par(mfrow=c(1,2))
  acf(SMICSta, main="Auto-Corrélation du SMIC
      trimestriel stationnarisé")
  pacf(SMICSta, main="Auto-Corrélation partielle du SMIC
      trimestriel stationnarisé")
  par(mfrow=c(1,1))
```

```{r, echo=F}
  kpss.test(SMICSta)
  adf.test(SMICSta)
```
\newpage
### Taux de chômage des femmes

```{r, fig.width=5, fig.height=4, fig.cap="\\label{fig17} Taux de chômage trimestriel stationnarisé", echo=F}
  TCHOFSta <- na.omit(decompose(TCHOFTrain)$random)
  plot(TCHOFSta, main="Taux de chômage des femmes 
       trimestriel stationnarisé", xaxt="n", cex.main=0.8)
  axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
```

En ce qui concerne le taux de chômage des femmes, en regardant l'ACF, PACF, le test de KPSS et le test de Dickey Fuller augmenté présents en Figure \ref{fig18}, on peut conclure que la série résiduelle est stationnaire.

```{r, fig.height=2.5, fig.cap="\\label{fig18} Fonctions d'autocorrélation du taux de chômage stationnarisé", echo=F}
  par(mfrow=c(1,2), cex.main=0.8)
  acf(TCHOFSta, main="Auto-Corrélation du Taux de
      chômage des femmes
      trimestriel stationnarisé")
  pacf(TCHOFSta, main="Auto-Corrélation partielle
      du Taux de chômage des femmes
      trimestriel stationnarisé")
  par(mfrow=c(1,1))
  kpss.test(TCHOFSta)
  adf.test(TCHOFSta)
```
\newpage
##Corrélation entre les variables stationnarisées

```{r, fig.width=4, fig.height=3, fig.cap="\\label{fig19} Corrélations entre les variables trimestrielles stationnarisées", echo=F}
corrplot(cor(cbind(MSESta, PIBSta, SMICSta, TCHOFSta)), method = "number", type="lower",
         p.mat=cor.mtest(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), 0.95)[[1]], insig="n",
         col=colorRampPalette(c("blue", "light blue", "red"))(50), title = "
         Corrélations entre les variables trimestrielles")
```

```{r, echo=F}
corr <- cor.mtest(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), 0.95)[[1]]
rownames(corr) <- c("MSE","PIB","SMIC","TCHOF")
colnames(corr) <- c("MSE","PIB","SMIC","TCHOF")
corr
```

On s'aperçoit que la transformation de nos séries a permis de supprimer les corrélations entre elles. En effet, la matrice des corrélations présentes en Figure \ref{fig19} nous montre que la corrélation la plus élevée vaut 0.14 ce qui reste très faible. De plus, en regardant le tableau des p-values, l'hypothèse nulle de non significativité du coefficient de corrélation n'est rejetée pour aucun couple de variables (avec un seuil de 5%).

Maintenant que toutes les séries ont été stationnarisées, elles peuvent être utilisées pour construire un modèle VAR.

## Mise en place de modèles VAR avec le package vars

Le package **vars** a été construit par Bernhard Pfaff [@vars]. Il permet de construire des modèles vectoriels (VAR), et dispose également des différentes fonctions de diagnostics permettant de vérifier que les hypothèses du modèle sont bien remplies. La version utilisée est la version 1.5-3 et date du 6 Août 2018.

### Calcul de l'ordre p

Afin de mettre en place une modélisation VAR, nous devons dans un premier temps nous intéresser à l'ordre p du modèle VAR. L'ordre p correspond à l'ordre de l'opérateur de retard, c'est-à-dire le nombre de valeurs du passé qui ont un impact sur la valeur à un instant t. Dans le package **vars**, la fonction *VARselect* permet de déterminer l'ordre des modèles VAR à selectionner en fonction de 4 critères (AIC, HQ, SC et FPE).

Pour les critères suivants, p correspond à l'ordre du modèle VAR, T le nombre d'observations utilisées pour la phase d'apprentissage, K le nombre de variables et $\tilde{\Sigma}_u (p) = \frac{1}{T} \Sigma_{t=1}^T \hat{u}_t \hat{u}_t'$ (la matrice de covariance des résidus du modèle).

Dans cette partie, nous développerons le fonctionement de la méthodologie en l'appliquant uniquement au modèle complet, soit celui prenant en compte les variables PIB, SMIC et taux de chômage des femmes.

```{r, fig.height=3.75, fig.cap="\\label{fig20} Critères associés au modèle complet", echo=F}
selec <- VARselect(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), lag.max=10)
par(mfrow=c(2,2))
plot(seq(1:10),t(selec$criteria[1,]), type="l", main="Evolution de l'AIC en
     fonction de l'ordre",
     xlab="Ordre", ylab="AIC")
abline(v=which.min(selec$criteria[1,]), col="blue")
plot(seq(1:10),t(selec$criteria[2,]), type="l", main="Evolution du critère HQ
     en fonction de l'ordre",
     xlab="Ordre", ylab="HQ")
abline(v=which.min(selec$criteria[2,]), col="blue")
plot(seq(1:10),t(selec$criteria[3,]), type="l", main="Evolution du SC en
     fonction de l'ordre",
     xlab="Ordre", ylab="SC")
abline(v=which.min(selec$criteria[3,]), col="blue")
```

Le critère AIC (Aikaike information criterion) se calcule, dans ce package, de la manière suivante : $AIC(p) = \ln \det(\tilde{\Sigma}_u(p)) + \frac{2}{T}p K^2 \quad$. L'objectif est de minimiser ce critère. Cela suppose donc que le déterminant de la matrice $\tilde{\Sigma}_u(p)$ soit strictement positif. Ce critère est asymptotiquement effiace : si le nombre d'observations tend vers l'infini, sa variance est aussi faible que possible.

Le critère HQ (Hannan-Quinn criterion) se calcule, dans ce package, de la manière suivante : $HQ(p) = \ln \det(\tilde{\Sigma}_u(p)) + \frac{2 \ln(\ln(T))}{T}p K^2 \quad$. L'objectif est de minimiser ce critère. Encore une fois, cela suppose que le déterminant de la matrice $\tilde{\Sigma}_u(p)$ soit strictement positif.

Le critère SC (Schwarz criterion) se calcule dans ce package de la manière suivante : $SC(p) = \ln \det(\tilde{\Sigma}_u(p)) + \frac{\ln(T)}{T}p K^2 \quad$. L'objectif est de minimiser ce critère. Ce critère est un autre nom du BIC.

On s'aperçoit que les différents critères à notre disposition, visibles sur les graphiques de la Figure \ref{fig20}, nous donnent des ordres à choisir différents. Ainsi, le meilleur AIC correspond à un modèle d'ordre 10, le meilleur HQ à un modèle d'ordre 3 et le meilleur SC à un modèle d'ordre 2. L'ordre de l'AIC étant trop grand (car trop de coefficients à estimer par rapport au nombre d'observations à notre disposition), nous ne souhaitons pas conserver cet ordre. De plus, on se rend compte que l'AIC du modèle avec un ordre 10 est similaire à celle d'un modèle avec un ordre 4. Les modèles HQ et SC sont meilleurs avec respectivement un ordre 3 et 2. Nous allons donc, dans la suite de l'analyse, essayer les trois modèles définit par les différents critères : ici, nous allons donc nous intéresser aux modèles d'ordre 2, 3 et 4.

### Estimation du modèle VAR(p)

Dans la partie précédente, nous avons sélectionné le meilleur ordre pour notre  modèle VAR. Il s'agit maintenant d'estimer différents modèles afin de pouvoir prédire la MSE. L'exemple que nous avons pris est pour le modèle complet, avec les trois ordres déterminés précédemment (2, 3 et 4). 

Un modèle VAR s'écrit sous la forme suivante : 

  $y_t = \sum_{i = 1}^{p} {A_iy_{t-i}} + u_t$

$A_i$ représentent les matrices de coefficients du modèle pour un ordre i, t le décalage de la série et $u_t$ une matrice K-dimensionnelle composée des résidus du modèle (indépendants et identiquement distribués).

####Ordre 4

Dans le package **vars**, la fonction utilisée pour construire des modèles VAR est VAR, qui prend en entrée la série temporelle multivariée, l'ordre du processus et le type de régresseurs à inclure. Dans notre cas, *type* vaut *const* car la série est stationnarisée et donc centrée en une constante $\mu$. Ci-dessous, le modèle d'ordre 4.

```{r, echo=F}
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4, type="const")
```

Les coefficients du modèle sont les suivants. Les erreurs standards associées sont présentes en Annexe \ref{Annexe3}.

```{r, echo=F}
A1<-rbind(modele$varresult$MSESta$coefficients[1:4], 
          modele$varresult$PIBSta$coefficients[1:4], 
          modele$varresult$SMICSta$coefficients[1:4],
          modele$varresult$TCHOFSta$coefficients[1:4])
colnames(A1)<-rownames(A1)<-c("MSE", "PIB", "SMIC", "TCHOF")
A1
A2<-rbind(modele$varresult$MSESta$coefficients[5:8], 
          modele$varresult$PIBSta$coefficients[5:8], 
          modele$varresult$SMICSta$coefficients[5:8],
          modele$varresult$TCHOFSta$coefficients[5:8])
colnames(A2)<-rownames(A2)<-c("MSE", "PIB", "SMIC", "TCHOF")
A2
A3<-rbind(modele$varresult$MSESta$coefficients[9:12], 
          modele$varresult$PIBSta$coefficients[9:12], 
          modele$varresult$SMICSta$coefficients[9:12],
          modele$varresult$TCHOFSta$coefficients[9:12])
colnames(A3)<-rownames(A3)<-c("MSE", "PIB", "SMIC", "TCHOF")
A3
A4<-rbind(modele$varresult$MSESta$coefficients[13:16],
          modele$varresult$PIBSta$coefficients[13:16],
          modele$varresult$SMICSta$coefficients[13:16],
          modele$varresult$TCHOFSta$coefficients[13:16])
colnames(A4)<-rownames(A4)<-c("MSE", "PIB", "SMIC", "TCHOF")
A4

A0<-c(modele$varresult$MSESta$coefficients[17], 
          modele$varresult$PIBSta$coefficients[17], 
          modele$varresult$SMICSta$coefficients[17],
          modele$varresult$TCHOFSta$coefficients[17])
names(A0)<-c("MSE", "PIB", "SMIC", "TCHOF")
```

Les indicateurs de qualité du modèle sont présents ci-dessous.

```{r, echo=F}
selection<-VARselect(cbind(MSESta, PIBSta, SMICSta, TCHOFSta))
selection$criteria[,4]
```

Enfin, l'erreur quadratique moyenne de ce modèle pour les données prédites est la suivante :

```{r, fig.width=4, fig.height=3.5, fig.cap="\\label{fig21} Comparaison entre les vraies valeur et le modèle complet pour un ordre 4", echo=F}
ordre4 <- forecast(VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4, type="const"))
EQM(MSETest, ordre4$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest)
plot(MSETest, xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(ordre4$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest, col="red")
```

La représentation graphique de la Figure \ref{fig21} nous montre des prédictions proches des vraies valeurs, à part pour le premier trimestre 2017.

####Ordre 3

On s'intéresse ensuite au modèle d'ordre 3, soit celui avec le meilleur critère HQ.

```{r, include=F}
modele2<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3, type="const")
```

Les coefficients du modèle associés à un retard de 1 sont les suivants :

```{r, echo=F}
A1modele2<-rbind(modele2$varresult$MSESta$coefficients[1:4], 
          modele2$varresult$PIBSta$coefficients[1:4], 
          modele2$varresult$SMICSta$coefficients[1:4],
          modele2$varresult$TCHOFSta$coefficients[1:4])
colnames(A1modele2)<-rownames(A1modele2)<-c("MSE", "PIB", "SMIC", "TCHOF")
A1modele2
```

Les indicateurs de qualité du modèle sont présents ci-dessous.

```{r, echo=F}
selection<-VARselect(cbind(MSESta, PIBSta, SMICSta, TCHOFSta))
selection$criteria[,3]
```

L'erreur quadratique moyenne de ce modèle pour les données prédites est la suivante :

```{r, fig.width=4.5, fig.height=3.75, fig.cap="\\label{fig22} Comparaison entre les vraies valeur et le modèle complet pour un ordre 3", echo=F}
ordre3 <- forecast(modele2, h=8)
EQM(MSETest, ordre3$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest)
plot(MSETest, xaxt='n')
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(ordre3$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)), col="red")
```

Graphiquement, la Figure \ref{fig22} associée à l'ordre 3 nous donne des prédictions semblant inférieures à celles du modèle d'ordre 4. L'apport d'un lag supplémentaire dans la construction du retard a donc bien une importance dans la qualité des prédictions.

####Ordre 2

Enfin, nous construisons le modèle avec le meilleur BIC, soit celui d'ordre 2.

```{r, include=F}
modele3<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=2, type="const")
```

Les coefficients du modèle associés à un retard de 1 sont les suivants :

```{r, echo=F}
A1modele3<-rbind(modele3$varresult$MSESta$coefficients[1:4], 
          modele3$varresult$PIBSta$coefficients[1:4], 
          modele3$varresult$SMICSta$coefficients[1:4],
          modele3$varresult$TCHOFSta$coefficients[1:4])
colnames(A1modele3)<-rownames(A1modele3)<-c("MSE", "PIB", "SMIC", "TCHOF")
A1modele3
```

Les indicateurs de qualité du modèle sont présents ci-dessous.

```{r, echo=F}
selection<-VARselect(cbind(MSESta, PIBSta, SMICSta, TCHOFSta))
selection$criteria[,2]
```

L'erreur quadratique moyenne de ce modèle pour les données prédites est la suivante :

```{r, fig.width=5, fig.height=4, fig.cap="\\label{fig23} Comparaison entre les vraies valeur et le modèle complet pour un ordre 2", echo=F}
ordre2 <- forecast(modele3, h=8)
EQM(MSETest, ordre2$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest)
plot(MSETest, xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(ordre2$forecast$MSESta$mean*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)), col="red")
```

Lorsque l'on compare les erreurs quadratiques moyennes, nous remarquons que la plus faible est celle associée à un modèle d'ordre 4, soit celui avec le meilleur AIC. Il nous faut maintenant vérifier que les hypothèses associées à ce modèle soient bien vérifiées.

### Verification de la stabilité

Pour vérifier si le processus VAR est stable, c'est-à-dire qu'il génère des séries stationnaires, nous devons calculer les valeurs propres de la matrice des coefficients : 

$$A = \begin{bmatrix}
A_1 & A_2 & \cdots & A_{p-1} & A_p \\
I & 0 & \cdots & 0 & 0 \\
0 & I & \cdots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \cdots & I & 0 
\end{bmatrix}$$

Si les modules des valeurs propres de A sont inférieures à 1, alors le processus VAR est stable. Nous allons donc vérifier que le processus VAR(4) créé précédemment avec toutes les variables à notre disposition est bien stable.

```{r, fig.width=5, fig.height=4, fig.cap="\\label{fig24} Valeurs propres de la matrice A", echo=F}
#Construction de la matrice A
A <- matrix(0,nrow=16, ncol=16)
A[1:4,1:4] = A1
A[1:4,5:8] = A2
A[1:4,9:12] = A3
A[1:4,13:16] = A4
A[5:8,1:4] = diag(1,4,4)
A[9:12,5:8] = diag(1,4,4)
A[13:16,9:12] = diag(1,4,4)
#Calcul des valeurs propres
vp <- eigen(A)
Mod(vp$values)
plot(seq(1,16), Mod(vp$values), xlab="",
     ylab="Modules des valeurs propres", ylim=c(0,1.5))
abline(h=1, col="red")
```

On s'aperçoit que tous les modules sont inférieurs à 1 sur le graphique de la Figure \ref{fig24}, le processus VAR(4) est donc stable.

### Test ARCH (homoscédasticité des résidus)

Le test multivarié de ARCH-LM permet de tester l'homoscédasticité des résidus. La statistique de test est la suivante : $VARCH_{LM}(q) = \frac{1}{2}TK(K+1)R_m^2$, où $R_m^2 = 1 - \frac{2}{K(K+1)}tr(\hat{\Omega}\hat{\Omega}_O^{-1})$, et $\hat{\Omega}$ est la matrice de covariance de la régression suivante : $vech(\hat{u_t}\hat{u_t}^T) = \beta_0 + B_1 vech(\hat{u}_{t-1}\hat{u}_{t-1}^T) + ... + B_q vech(\hat{u}_{t-q}\hat{u}_{t-q}^T) + v_t$. La dimension de $\beta_O$ est $\frac{1}{2}K(K+1)$ et celle des matrices des coefficients $B_i$ est $\frac{1}{2}K(K+1) × \frac{1}{2}K(K+1)$. La statistique de test suit une loi de $\chi^2(qK^2(K+1)^2/4)$, donc dans notre cas $\chi^2(16q*25/4)$. L'hypothèse nulle de ce test est $H_0 : B_0 = B_1 = ... = B_q = 0$ (homoscédasticité).

```{r, fig.width=4.5, fig.height=3.75, fig.cap="\\label{fig25} Evolution de la p-value en fonction du lag", echo=F}
a1 <- c()
for(i in 1:18){
a1[i] <- arch.test(modele, lags.multi = i)$arch.mul$p.value
}
plot(a1, type="l", xlab="lag", ylab="p-value")
abline(h=0.05, col="red")
```

On s'aperçoit au regard de la figure \ref{fig25}, avec un seuil de confiance de 5% (ligne rouge), qu'on rejette l'hypothèse nulle d'homoscédasticité pour un retard faible (inférieur à 7). Cependant, en augmentant le nombre de valeurs prises en compte pour calculer la nouvelle, on se rend compte qu'on conserve l'hypothèse d'homoscédasticité. On observe également que la valeur de la p-value converge vers 1 au fur et à mesure qu'on augmente le retard. Ainsi, en prenant l'ensemble des résidus, nous conservons l'hypothèse d'homoscédasticité.

### Test normalité (normalité des résidus)

Le test de Jarque-Bera pour séries multivariées permet de tester la normalité des résidus. Il utilise les résidus standardisés à l'aide d'une décomposition de Cholesky de la matrice de variance-covariance des résidus centrés. Il est important noter que l'ordre dans lequel les variables sont stockées dans la matrice a une importance sur les résultats. La statistique de test est la suivante : $JB_{mv} = s_3^2 + s_4^2$, où $s_3^2$ et $s_4^2$ se calculent de la sorte : $s_3^2 = Tb_1^Tb_1/6$ et $s_4^2 = T(b_2 - 3_K)^T(b_2-3_K)/24$, avec $b_1$ et  $b_2$ qui sont respectivement les vecteurs des moments non-centrés d'ordre trois et quatre des résidus standardisés. La statistique de test suit une loi de $\chi^2(2K)$. Ce test compare en fait le coefficient Kurtosis K (l'aplatissement de la fonction de densité) et le coefficient Skewness S (asymétrie de la fonction de densité) d'une loi normale à ceux des résidus testés. L'hypothèse nulle est donc $H0 : S = 0$ et $K = 3$.

```{r, echo=F}
normality.test(modele)$jb.mul$JB
```

Ici, on rejette l'hypothèse H0, avec un seuil de confiance de 5%. Les résidus obtenus ne suivent pas une loi normale. Cependant ce test à tendance à rejeter facilement les jeux de données ne possédant que peu de données, ce qui est le cas ici. Les résultats de ce test ne sont donc pas forcément crédibles dans ce contexte.

### Test Portmanteau (corrélations des résidus)

Le test de Portmanteau multivarié permet de tester l'auto-corrélation (au sein d'une même série) et la corrélation croisée (entre les différentes séries) des résidus.

#### Verification de la Matrice $C_0$

La statistique de Portmanteau est $Q_h = T \sum_{j=1}^h tr(\hat{C}_j^T \hat{C}_0^{-1} \hat{C}_j \hat{C}_0^{-1})$, et elle suit une loi de $\chi^2(K^2h - n^*)$, $n^*$ étant le nombre de coefficients à estimer. Pour qu'elle existe, il faut donc vérifier que la matrice $\hat{C}_0$ est inversible pour que la statistique puisse être définie. Les matrices $\hat{C}_i$ s'écrivent $\hat{C}_i = \frac{1}{T} \sum_{t=i+1}^T \hat{u}_t \hat{u}_{t-i}^T$, donc $\hat{C}_0$ s'écrit $\hat{C}_0 = \frac{1}{T} \sum_{t=1}^T \hat{u}_t \hat{u}_t^T$. Nous allons donc vérifier qu'elle est inversible pour le modèle complet que nous avons mis en place. $tr()$ correspond à la trace de la matrice, soit la somme des éléments diagonaux de la matrice.

```{r, echo=F}
C0 <- matrix(nrow = 4, ncol=4, 0)
for(i in 1:nrow(residuals(modele))){
  C0 <- C0 + residuals(modele)[i,]%*%t(residuals(modele)[i,])
}
C0 <- (1/nrow(residuals(modele))) * C0
C0
d <- det(C0)
names(d) <- "Déterminant de la matrice"
d
```

Même si le déterminant est très faible, il n'est pas nul. La matrice $\hat{C}_0$ est donc inversible.

#### Application du test

Les 3 premières p-values ne peuvent être calculées à cause de la valeur des degrés de liberté. En effet, comme nous l'avons expliqué plus haut, la statistique de test suit une loi de $\chi^2(K^2h - n^*)$. Or, avec un retard compris entre 1 et 3, les degrés de liberté sont négatifs et il n'est donc pas possible d'appliquer le test. L'hypothèse nulle de ce test est l'absence de corrélations croisées et d'auto-corrélations.

```{r, , fig.width=4, fig.height=3, fig.cap="\\label{fig26} Evolution de la p-value en fonction du lag", echo=F}
a1 <- c()
for(i in 1:3){
  a1[i] <- NA
} 
for(i in 4:50){
  a1[i] <- serial.test(modele, lags.pt=i, type="PT.asymptotic")$serial$p.value
}
plot(a1, type="l", xlab="lag", ylab="p-value")
abline(h=0.05, col="red")
```

Au regarde la figure \ref{fig26} Comme pour le test ARCH, on rejette l'hypothèse nulle, avec un seuil de confiance à 5% (ligne rouge) pour un retard faible (5 ou moins). Cependant, pour un retard grand (supérieur à 5), on conserve l'hypothèse nulle d'absence d'auto-corrélations et de corrélations croisées. On observe également que la p-value converge vers 1 à mesure qu'on augmente le retard. Ainsi, en prenant en compte l'ensemble des résidus, on conserve l'hypothèse d'absence d'auto-corrélations et de corrélations croisées.

### Prévisions

Maintenant que nous avons estimé l'ordre des différents modèle VAR, et que nous avons explicité l'estimation des modèles, nous cherchons désormais à trouver celui dont les prédictions sont les plus proches de la réalité.

Après avoir comparé tous les modèles possibles (7 : 3 modèles avec deux variables, 3 modèles avec trois variables et un modèle avec les quatre variables), nous nous apercevons que le meilleur en terme de prédictions est le modèle complet, soit celui que nous avions pris en exemple. Les AIC et EQM des différents modèles sont résumés dans le tableau ci-dessous. 

|  Variables utilisées   | Ordre |    AIC    |     EQM      |
| ---------------------- | ----- | ----------| -------------|
| MSE & PIB              |   4   | -20.85328 | 9.153141e+14 |
| MSE & SMIC             |   3   | -15.37233 | 9.553417e+14 |
| MSE & TCHOF            |   3   | -12.44526 | 9.880360e+14 |
| MSE, PIB & SMIC        |   3   | -27.65284 | 9.564856e+14 |
| MSE, PIB & TCHOF       |   4   | -24.98222 | 9.020987e+14 |
| MSE, SMIC & TCHOF      |   4   | -19.20940 | 7.955221e+14 |
| MSE, PIB, SMIC & TCHOF |   4   | -31.74520 | 7.711856e+14 |

\newpage
##Mise en place de modèles VAR avec le package MTS
```{r, include=F}
require(MTS)
```

Le package **MTS** a été créé par **Ruey S. Tsay** and **David Wood**, professeurs à l'université de Chicago [@MTS]. Contrairement au package **vars**, il ne se limite pas aux modèles VAR et propose également d'autre types de modèles multivariés, tels que des modèles de type VMA (Vector Moving Average), VARMA et même quelques modèles de fonctions de transfert, que nous n'avons pas eu l'occasion d'étudier. Ce package est très récent, sa première version datant du 8 octobre 2018.

Pour nous aider à comprendre l'utilisation de ce package, nous nous somme beaucoup inspirés de l'article *Multivariate Time Series Analysis with R and Financial Applications* de **Ruey S.Tsay**

### Calcul de l'ordre p

Afin de mettre en place une modélisation VAR, nous devons dans un premier temps nous intéresser à l'ordre p du modèle VAR. Dans le package **MTS**, la fonction utilisée est VARorder, qui comme VARselect utilise les critères d'AIC, BIC et HQ afin de déterminer l'ordre du processus.

Cependant, nous avons également en notre possession un autre critère, la statistique du test de Tiao-Box ainsi que sa p-value. Ce test évalue pour un ordre *i* la significativité des coefficients de la matrice $A_i$. Ce test permet donc de déterminer si le modèle d'ordre *i* est meilleur que celui d'ordre *i-1*. La statistique de test est la suivante : $M(i) = -(T-K-i-\frac{3}{2}) \ln(\frac{det(\hat{\Sigma}_1)}{det(\hat{\Sigma}_{i-1})})$, qui suit une loi du $\chi^2_{k^2}$. Dans l'exemple que nous prenons, la première p-value supérieure à 0.05 est celle pour la matrice $A_5$. L'ordre que nous devons retenir par rapport à ce test est donc 4.

```{r, echo=F}
VARorder(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), maxp = 10)
```

Comme pour le package VARS, l'AIC associé aux différents modèles diminue en même temps que l'ordre augmente. Si l'on conserve un ordre raisonnable, le meilleur AIC est également pour un modèle d'ordre 4. Le BIC nous donne lui un modèle d'ordre 2 alors que le critère HQ nous conseille d'utiliser un modèle d'ordre 3. Cela correspond aux mêmes ordres que ceux données par le package **vars**.

### Estimation du modèle

Dans le package **MTS**, la fonction utilisée pour construire des modèles VAR est *VAR*, qui prend en entrée la série temporelle multivariée et l'ordre du processus. On affiche ci-dessous les résultats renvoyés par la fonction sur le modèle d'ordre 4, soit les coefficients du modèle pour chaque ordre de retard, les erreurs standard ainsi que les valeurs des critères de qualité.
```{r, echo=F}
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4)
```

Les résultats associés aux modèles d'ordre 3 et 2 sont eux présents en Annexe \ref{Annexe4} et en Annexe \ref{Annexe5}. Comme pour le package **vars**, il nous faut maintenant vérifier les hypothèses du modèle.

### Vérification des hypothèses

#### Vérification de la stabilité

Comme pour le package **vars**, nous vérifions que les modules des valeurs propres de la matrice A sont tous inférieurs à 1 . R. Tsay définit cependant la matrice A différemment de B. Pfaff, soit en la retournant

$$A = \begin{bmatrix}
0 & I & 0 & \cdots & 0 \\
0 & 0 & I & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 0 & I \\
A_p & A_{p-1} & A_{p-2} & \cdots  & A_1 
\end{bmatrix}$$

```{r, fig.width=4.25, fig.height=3, fig.cap="\\label{fig27} Valeurs propres associées à la matrice A", echo=F}
stabilityMTS(modele)
```

La Figure \ref{fig27} nous montre des valeurs propres toutes inférieures à 1 en module ce qui nous permet de prouver la stabilité du modèle.

#### Autocorrélation et corrélation croisée

Nous vérifions ensuite que les résidus ne comportent ni d'autocorrélation, ni de corrélation croisée. Pour cela, on utilise la fonction *ccm*, qui vérifie les matrices de corrélation croisée pour un lag donné. On définit la matrice de variance-covariance pour un lag *p* comme $\hat{\Gamma}_p = \frac{1}{T}\sum_{i=p+1}^{T} (r_t - \bar{r})(r_{t-p} - \bar{r})$. La matrice de corrélation associée vaut donc $\rho_p = \hat{D}^{-1}\hat{\Gamma}_p\hat{D}^{-1}$.

```{r, fig.width=4, fig.height=3, fig.cap="\\label{fig28} Significativité des corrélations croisées pour un lag de 1 à 10", echo=F}
crossCorr<-ccm(modele$residuals, lag=10, output=F)
plot(crossCorr$pvalue, xlab = "lag", ylab = "p-value", ylim = c(0,1), main="Significance plot of CCM")
abline(h = 0)
crit = 2/sqrt(length(modele$residuals))
abline(h = crit, lty = 2, col="red")
```

La Figure \ref{fig28} représente le résultat du test d'égalité de la matrice $\hat{\Gamma}_p$ à 0. On considère que la corrélation est significative si elle dépasse le seuil de $2/\sqrt{T}$ avec T la longueur de la série. On ne rejette pas l'hypothèse nulle peu importe le lag, ce qui nous indique que les résidus ne comporte pas de corrélation croisée. 

Nous effectuons ensuite le test de Ljung-Box multivarié, qui teste à la fois l'autocorrélation et la corrélation croisée. La statistique de ce test est $Q_h = T^2 \sum_{j=1}^h \frac{1}{t-j} tr(\hat{C}_j^T \hat{C}_0^{-1} \hat{C}_j \hat{C}_0^{-1})$, et elle suit une loi de $\chi^2(K^2h)$. C'est donc la même statistique que pour le package **vars** à un coefficient près.

```{r, fig.width=5, fig.height=4, fig.cap="\\label{fig29} Evolution de la p-value en fonction du lag", echo=F}
mq(modele$residuals, lag=10)
```

Le résultat de ce test, dont la visualisation graphique est présente ci-dessus, permet également de conclure que les résidus suivent un bruit blanc. 

###Prévisions

Comme pour le package précédent, nous résumons dans le tableau suivant les informations sur les modèles construits. Encore une fois, le plus performant est le modèle comprenant toutes les variables. On note également que les EQM obtenues sont identiques à celles du package **vars**. Les AIC sont sensiblement les mêmes mais non identiques, en raison de méthodes de calcul différentes.

|  Variables utilisées   | Ordre |    AIC    |     EQM      |
| ---------------------- | ----- | ----------| -------------|
| MSE & PIB              |   4   | -20.9333  | 9.153141e+14 |
| MSE & SMIC             |   3   | -15.4434  | 9.553417e+14 |
| MSE & TCHOF            |   6   | -12.5389  | 9.880360e+14 |
| MSE, PIB & SMIC        |   3   | -27.7795  | 9.564856e+14 |
| MSE, PIB & TCHOF       |   4   | -25.1289  | 9.020987e+14 |
| MSE, SMIC & TCHOF      |   4   | -19.3573  | 7.955221e+14 |
| MSE, PIB, SMIC & TCHOF |   4   | -31.9763  | 7.711856e+14 |

#Construction de modèles VARMA

A la fin du projet, nous avons cherché à ajouter une partie MA à nos modèles afin d'améliorer les prédictions. Le modèle s'écrit alors de la façon suivante : 

$y_t = \sum_{i = 1}^{p} {A_iy_{t-i}} + \sum_{i = 1}^{q}{M_iu_{t-i}}$

On rajoute donc au modèle AR une partie MA représentée par les matrices $M_0 ... M_q$. Ce type de modèle n'est que peu utilisé dans la pratique car il est difficile de satisfaire à la fois les hypothèses liées à la partie AR et celles liées à la partie MA. On lui préfère donc souvent un modèle AR, plus simple à construire.

Dans notre cas, la construction de modèle VARMA est possible grâce à la fonction *VARMA* du package **MTS**. 

##Calcul des ordres p et q

La méthode pour l'estimation des ordres p et q du modèles est un peu différente de celle pour un modèle VAR. En effet, nous utilisons cette fois les matrice de corrélation croisée étendues. Si le coefficient associée à la matrice de corrélation étendue est supérieur au seuil choisi (5% pour nous), alors un modèle peut être estimé. La fonction permettant de complier les matrices de corrélation croisée étendues est *Eccm*.
```{r, echo=F}
Eccm(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), maxp=5, maxq=5)
```

Pour le modèle complet, la matrice de corrélation croisée étendue devient significative à partir d'un modèle VARMA(3,0), soit un modèle VAR(3). Le but étant de rajouter une partie MA au modèle, les ordres retenus seront donc 3 et 1.

##Estimation du modèle

Cependant, les résultats obtenus, présents en Annexe \ref{Annexe6} du rapport, ne sont pas exploitables. En effet, de nombreux coefficients du modèles ne sont pas significatifs, potentiellement en raison du grand nombre de paramètres à estimer. Nous n'avons donc pas réussi à effectuer des prédictions avec ce modèle.

\newpage
#Prévisions sur les années suivantes

Maintenant que nous avons réalisé nos modèles, vérifié qu'ils satisfaisaient toutes les hypothèses de construction et comparé les prédictions de ces modèles aux valeurs de notre échantillon de test, nous effectuons quelques prédictions pour les années 2018, 2019, 2020 et 2021. Nous utilisons le modèle complet avec un ordre p=4 étant donné que c'est celui qui donnait les meilleurs résultats.
```{r, fig.width=6, fig.height=4, fig.cap="\\label{fig30} Prévisions du modèle VAR pour les années de 2016 à 2021", echo=F}
detach("package:MTS", unload=TRUE)
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4, type="const")
MSETrendTest <- window(forecast(na.omit(MSETrend), h=26)$mean, start=2016)
MSESeasonalTest<-ts(rep(MSESeasonal[1:4],6), start=2016, frequency=4)
pred<-window(forecast(modele, h=26)$forecast$MSESta$mean)
pred*MSETrendTest*MSESeasonalTest
plot(pred*MSETrendTest*MSESeasonalTest)
```

D'après le modèle, la masse salariale devrait baisser dans les années à venir, d'environ 10 millions chaque année par trimestre. Elle devrait donc par exemple être d'environ 1.44 milliard d'euros sur le trimestre prochain.

\newpage
#Conclusion {-}

Nous avons donc mis en place des modèles de la famille VAR sur le jeu de données à notre disposition. L'objectif était de regarder si ce type de modèle pouvait être appliqué en respectant les différents hypothèses sous-jacentes au modèle, et de regarder la qualité des prédictions du modèle s'il était possible de le construire.

Afin de mettre en place ce type de modèles, nous avons utilisé deux packages différents, à savoir vars et MTS, et nous nous rendons compte que les résultats des deux packages sont similaires.

Nous avons également tenté d'ajouter une composante moyenne-mobile pour former des modèles VARMA et regarder la qualité de ce type de modèle par rapport aux modèles VAR que nous avons mis en place. Malheureusement, les résultats de ces modèles n'étaient pas exploitables 

Afin de vérifier si la modélisatio vectorielle est la plus adapté pour les données de l'IRCEM, il serait bon  de comparer ces prédictions avec des modèles construits à l'aide de fonction de transfert, présents également dans le package **MTS**.

\newpage
\appendix

#Annexe 1 : Modélisation univariée des séries \label{Annexe1}

Une fois que nous avons analysé le comportement des différentes séries temporelles à notre disposition, nous souhaitons les modéliser afin de prédire les valeurs futures de ces différentes séries. En effet, si nous voulons prédire la MSE pour des valeurs futures, nous aurons également besoin des valeurs associées pour les variables explicatives, qui ne seront peut-être pas à notre disposition. Nous avons utilisé à la fois des modèles basés sur un lissage exponentiel et des processus ARMA. Nous nous sommes aidés pour ce faire des travaux de Nicolas Devignes [@Nicolas] lors d'un stage au laboratoire Paul Painlevé sur ce sujet.

##Comparaison des différents modèles
Afin de comparer les modèles construits pour chaque série avec les différentes méthodes, nous calculons l'Erreur Quadratique Moyenne (EQM), soit les moyennes des différences au carré entre les valeurs de test et les valeurs prédites par le modèle.

##Lissage exponentiel

###Définition

Le lissage exponentiel permet de prédire les valeurs d’une série temporelle en lissant successivement les données à partir d’une valeur initiale. Plus les observations sont éloignées dans le passé, moins leur poids est important lors du calcul. Pour une série stationnaire, la formule de calcul d’une valeur est la suivante :  $s_t =  \alpha y_t + (1-\alpha) s_{t-1}$, le paramètre $\alpha$ étant le facteur de lissage. Le nom de cette méthode est un lissage exponentiel **simple**. Afin de modéliser les séries possédant une tendance, nous introduisons un paramètre $\beta$ permettant de la prendre en compte, la méthode étant appelée lissage exponentiel **double**. Enfin, Holt et Winters ont également modifié la méthode pour qu’elle puisse modéliser les séries comportant une saisonnalité en introduisant un paramètre $\gamma$. Ils ont donné leur nom à cette méthode, qui est donc un lissage exponentiel de **Holt-Winters**.

Dans notre cas, nous ne calculons pas nous-mêmes $\alpha$, $\beta$ et $\gamma$ Ces paramètres sont déterminés automatiquement par la fonction *ets* du package **forecast** de façon à optimiser la qualité de la prédiction. Cette fonction permet également de choisir la méthode à utiliser, grâce à l'argument model. Afin de mesurer la qualité de notre modèle, nous avons choisi d'utiliser l’**AICc** (Akaike Information Criterion with correction). Le choix de l’AICc par rapport à l’AIC s’explique par le faible nombre de données que nous possédons par rapport au nombre de paramètres à estimer. C'est ce critère qui nous servira par la suite afin de comparer nos différents modèles. \label{AICc}

Prenons l'exemple de la MSE. Nous avons vu dans la partie \ref{MSE} que la série possédait une tendance linéaire ainsi qu'une saisonnalité multiplicative. L'argument model de la fonction *ets** prendra donc la valeur "ZAM", (erreur sélectionnée automatiquement, tendance linéaire, saisonnalité multiplicative). On peut également remarquer que lorsque tous les paramètres sont automatiquement sélectionnés (valeur "ZZZ"), les paramètres retenus sont les mêmes que ceux que nous avions rentré.

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig31} Comparaison entre la prédiction du lissage exponentiel et les valeurs réelles pour la masse salariale trimestrielle", echo=F}
LEMSE<-ets(MSETrain, "ZAM")
print(LEMSE)
PredLEMSE <- forecast(LEMSE, h = 6)
plot(MSETest, main="")
lines(PredLEMSE$mean, col="red")
EQM(MSETest, PredLEMSE$mean)
```

On obtient donc un AICc de 4033.451 pour le modèle ainsi qu'une erreur quadratique moyenne de $2.6*10^{14}$. Le graphique obtenu en figure \ref{fig31} nous montre que le modèle obtenu nous donne des prédictions très proches de la réalité.

###Résultats obtenus

```{r, include=F}
LEPIB<-ets(PIBTrain, "ZAN")
print(LEPIB)
PredLEPIB <- forecast(LEPIB, h = 5)
EQM(PIBTest, PredLEPIB$mean)

LESMIC<-ets(SMICTrain, "ZAA")
print(LESMIC)
PredLESMIC <- forecast(LESMIC, h = 6)
EQM(SMICTest, PredLESMIC$mean)

LETCHOF<-ets(TCHOFTrain, "ZNN")
print(LETCHOF)
PredLETCHOF <- forecast(LETCHOF, h = 6)
EQM(TCHOFTest, PredLETCHOF$mean)
```

```{r, fig.width=5, fig.height=5, fig.align='center', fig.cap="\\label{fig32} Résultats obtenus pour le lissage exponentiel", echo=F}
par(mfrow=c(2,2))
plot(PIBTest, ylim=c(min(PIBTest,PredLEPIB$mean),max(PIBTest,PredLEPIB$mean)), main=
"Comparaison entre la prédiction du lissage 
exponentiel et les valeurs réelles pour le PIB 
trimestriel", cex.main=0.8)
lines(PredLEPIB$mean, col="red")

plot(SMICTest, ylim=c(min(SMICTest,PredLESMIC$mean),max(SMICTest,PredLESMIC$mean)), 
main="Comparaison entre la prédiction du lissage 
exponentiel et les valeurs réelles pour le SMIC 
trimestriel", cex.main=0.8)
lines(PredLESMIC$mean, col="red")

plot(TCHOFTest, ylim=c(min(TCHOFTest,PredLETCHOF$mean),max(TCHOFTest,PredLETCHOF$mean)), 
main="Comparaison entre la prédiction du lissage 
exponentiel et les valeurs réelles pour le taux 
de chômage trimestriel", cex.main=0.8)
lines(PredLETCHOF$mean, col="red")
```

Les graphiques de la figure \ref{fig32} nous montrent des résultats mitigés. Pour le PIB et le SMIC, les prédictions suivent la forme de la série mais en sont éloignées. Pour le taux de chômage des femmes, la méthode de lissage utilisée est un lissage exponentiel simple, ce qui nous donne donc des prédictions constantes soit de mauvaise qualité. 

Nous résumons dans le tableau suivant les résultats obtenus pour chaque série estimée par un lissage exponentiel.

| Variable | Tendance |  Saisonnalité  | Argument model |   AIC   |
| -------- | -------- | -------------- | -------------- | ------- |
| MSE      | linéaire | multiplicative |      ZAM       | 4033.45 |
| PIB      | linéaire | absente        |      ZAN       | 2053.15 |
| SMIC     | linéaire | additive       |      ZAA       | -84.96  |
| TCHOF    | absente  | absente        |      ZNN       | 204.37  |
 
##Modèles ARMA

###Définition

Les modèles **ARMA(p,q)** sont une autre famille de modèles permettant d’estimer une série temporelle. Il est divisé en deux parties : une partie  autorégressive **AR** auquel est associé un ordre *p* qui donne le nombre de valeurs passées qui vont être utiles dans la prédiction, et une partie moyennes mobiles **MA** qui permet de de prendre en compte les *q* innovations de la série dans le futur.

L’une des propriétés des processus ARMA est qu’ils sont utilisés pour modéliser des séries stationnaires, donc par extension des séries qui ne possèdent ni tendance ni saisonnalité. Afin de modéliser des séries non stationnaires, on généralise les processus ARMA en processus **ARIMA(p,d,q)**, *d* représentant l’ordre de différenciation de la série. Les séries saisonnières sont elles modélisées par des processus **$SARIMA(p ,d, q)(P, D, Q)_s$** qui modélisent des séries avec une saisonnalité de période *s*.

Comme pour le lissage exponentiel, nous ne calculons pas nous-mêmes les ordres des processus. Pour cela, la fonction *auto.arima* du package **forecast** nous a été très utile. Elle permet en effet de trouver les ordres du processus qui optimisent un critère défini à l’avance et de calculer un modèle avec ces coefficients. Nous avons choisi d’optimiser l’**AICc**(Akaike Information Criterion with correction), pour les raisons évoquées dans la partie \ref{AICc}

```{r include=F}
ARIMAMSE<-auto.arima(MSETrain, ic="aicc")
print(ARIMAMSE)
PredARIMAMSE<- forecast(ARIMAMSE, h=6)
```

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig33} Comparaison entre le modèle SARIMA et les données de validation pour la masse salariale trimestrielle", echo=F}
plot(MSETest, main="")
lines(PredARIMAMSE$mean, col="red")
```

Pour la MSE, on obtient par exemple un modèle $SARIMA(0,1,1)(0,1,1)_4$ ainsi qu'un AICc de 3896.01. La  figure \ref{fig33} nous donne des prédictions d'assez bonne qualité mais qui semblent moins bonnes que celles obtenues par lissage exponentiel.

###Résultats obtenus

```{r, include=F}

ARIMAPIB<-auto.arima(PIBTrain, ic="aicc", seasonal=F)
print(ARIMAPIB)
PredARIMAPIB<- forecast(ARIMAPIB, h=5)

ARIMASMIC<-auto.arima(SMICTrain, ic="aicc")
print(ARIMASMIC)
PredARIMASMIC<- forecast(ARIMASMIC, h=6)

ARIMATCHOF<-auto.arima(TCHOFTrain, ic="aicc", seasonal=F)
print(ARIMATCHOF)
PredARIMATCHOF<- forecast(ARIMATCHOF, h=6)
```

```{r, fig.cap="\\label{fig34} Résultats obtenus avec des modèles ARMA", echo=F}
par(mfrow=c(2,2), cex.main=0.8)
plot(PIBTest, ylim=c(min(PIBTest,PredARIMAPIB$mean),max(PIBTest,PredARIMAPIB$mean)), 
main="Comparaison entre le modèle SARIMA et les données de
    validation pour le PIB trimestriel")
lines(PredARIMAPIB$mean, col="red")

plot(SMICTest, ylim=c(min(SMICTest,PredARIMASMIC$mean),max(SMICTest,PredARIMASMIC$mean)), 
main="Comparaison entre le modèle SARIMA et les données de
    validation pour le SMIC trimestriel")
lines(PredARIMASMIC$mean, col="red")

plot(TCHOFTest, main="Comparaison entre le modèle SARIMA et les données de
    validation pour le taux de chômage des femmes trimestriel")
lines(PredARIMATCHOF$mean, col="red")
```

Comme pour le lissage exponentiel, nous résumons les résultats obtenus dans un tableau pour plus de lisibilité. Le PIB et le taux de chômage des femmes ne comportent pas de partie saisonnière car comme vu dans les parties \ref{PIB} et \ref{TCHOF} on ne constate pas de saisonnalité dans l'analyse descriptive de la série. On peut également voir sur la figure \ref{fig34} que les prédictions du PIB semblent de bien meilleure qualité

| Variable | Ordre du processus |  AICc   |
| -------- | -------------------| ------- |
| MSE      |   (0,1,1)(0,1,1)   | 3675.34 |
| PIB      |       (2,1,0)      | 1839.36 |
| SMIC     |   (1,0,0)(1,1,0)   | -261.47 |
| TCHOF    |       (0,1,1)      |  9.76   |

##Comparaison des différents modèles

Une fois que nous avons construit les deux types de modèles pour chacune des variables, nous souhaitons les comparer pour savoir quel modèle est le plus efficace pour prédire chacune des variables. Pour cela, les EQM, calculant l'erreur de prédiction, de chacun des modèles sont synthétisées dans le tableau suivant. L'AICc ne peut pas être utilisé ici car les méthodes à comparer sont différentes. Il n'est donc pas sûr que la méthode utilisée pour calculer la vraisemblance soit la même.

```{r, echo=F}
resultats<-matrix(nrow=4, ncol=2, dimnames = list(c("MSE", "PIB", "SMIC", "TCHOF"), 
                                                  c("lissage", "ARMA")))
resultats[1,1] = EQM(MSETest, PredLEMSE$mean)
resultats[2,1] = EQM(PIBTest, PredLEPIB$mean)
resultats[3,1] = EQM(SMICTest, PredLESMIC$mean)
resultats[4,1] = EQM(TCHOFTest, PredLETCHOF$mean)
resultats[1,2] = EQM(MSETest, PredARIMAMSE$mean)
resultats[2,2] = EQM(PIBTest, PredARIMAPIB$mean)
resultats[3,2] = EQM(SMICTest, PredARIMASMIC$mean)
resultats[4,2] = EQM(TCHOFTest, PredARIMATCHOF$mean)
resultats
```

Nous nous rendons compte que le lissage a une EQM plus faible pour la masse salariale (notre variable d’intérêt), ainsi que pour le SMIC et le taux de chômage des femmes. En ce qui concerne le PIB, le modèle ARIMA est plus performant. Cette analyse va nous servir par la suite, comme expliqué au début de l'Annexe \ref{Annexe1}

# Annexe 2 : Modélisation ARMA avec variables exogènes \label{Annexe2}

## Définition

Maintenant que nous avons modélisé chaque série individuellement, nous souhaitons savoir s’il est possible d’améliorer la qualité de prédiction de la série MSE trimestrielle à l’aide des autres variables à notre disposition. Pour ce faire, nous allons construire des modèles SARIMA prenant en compte des variables exogènes. 

$Y_{t} = \beta_{0} +\beta_{1}X_{1t} + ... + \beta_{k}X_{kt} + \epsilon_{t}$

$Y_{t}$ est la variable à modéliser. $X_{i}$ pour $i = 1, ..., k$ correspond à la $i$ème variable exogène. $\beta_{i}$ pour i allant de $i = 0, ..., k$ correspond aux coefficients d'une régression linéaire. Enfin, le résidu $\epsilon_{t}$ suit un processus de type ARMA.

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig35} Masse salariale expliquée par le PIB, le SMIC et le taux de chômage vs Vraies valeurs", echo=F}
#PIB & SMIC & TCHO
SARIMACOMPLET <- auto.arima(MSETrain, xreg = cbind(PIBTrain, SMICTrain, TCHOFTrain))
PredCOMPLET <- forecast(SARIMACOMPLET, xreg = cbind(PIBTest, SMICTest, TCHOFTest))
plot(PredCOMPLET$mean, col="red",
     ylim=c(min(MSETest,PredCOMPLET$mean), max(MSETest,PredCOMPLET$mean)),
     main = "")
lines(MSETest)
EQM(PredCOMPLET$mean, MSETest)
```

Ici, les résidus suivent un SARIMA(0,0,0)(0,1,0)[4], et le modèle possède 3 variables exogènes : le coefficient correspondant à la variable PIB est $\beta_1 = 706.0045$, celui correspondant à la variable SMIC est $\beta_2 = 209266766$ et enfin celui correspondant au taux de chômage est $\beta_3 = -1644706$

## Résultats obtenus

Nous allons désormais nous intéresser à la construction des différents modèles prenant en compte 1 variable exogène (3 modèles), 2 variables exogènes (3 modèles) et 3 variables exogènes (1 modèle). La qualité de ces 7 modèles est representée dans le tableau ci-dessous.

| Variable     | Ordre du processus |  AICc   | EQM          |
| ------------ | -------------------| ------- | ------------ |
| PIB          |   (1,0,0)(2,1,0)   | 3715.99 | 1.170337e+15 |
| SMIC         |   (0,1,0)(0,1,0)   | 3688.92 | 6.219316e+14 |
| TCHOF        |   (0,0,0)(1,1,0)   | 3809.82 | 1.949846e+15 |
| PIB & SMIC   |   (0,0,0)(0,1,0)   | 3807.37 | 1.330526e+15 |
| PIB & TCHOF  |   (1,0,0)(0,1,0)   | 3721.36 | 7.424654e+14 |
| SMIC & TCHOF |   (0,1,0)(0,1,0)   | 3690.57 | 5.586871e+14 |
| COMPLET      |   (0,0,0)(0,1,0)   | 3809.5  | 1.324892e+15 |

On se rend compte qu'aucun modèle ARIMA ne prenant en compte des variables exogènes n'a une qualité meilleure que celui ne prenant en compte aucune variable exogène (en comparant les AIC corrigés). Si on omet le modèle sans variable exogène, le meilleur modèle prenant en compte au moins une variable exogène est celui prenant en compte le SMIC et le taux de chômage (dans la figure \ref{fig36}).

```{r, fig.width=5, fig.height=4, fig.align='center', fig.cap="\\label{fig36} SARIMA expliqué par le SMIC et le taux de chômage vs Vraies valeurs", echo=F}
#SMIC
SARIMASMICTCHOF <- auto.arima(MSETrain, xreg = cbind(SMICTrain, TCHOFTrain))
PredSMICTCHOF <- forecast(SARIMASMICTCHOF, xreg = cbind(SMICTest, TCHOFTest))
plot(PredSMICTCHOF$mean, col="red",
     ylim=c(min(MSETest,PredSMICTCHOF$mean), max(MSETest,PredSMICTCHOF$mean)))
lines(MSETest)
EQM(PredSMICTCHOF$mean, MSETest)
```

#Annexe 3 : Erreurs standard associées aux coefficients du modèle VAR d'ordre 4 \label{Annexe3}

```{r, echo=FALSE}
#Calcul des erreurs standards associées aux matrices A1, A2, A3 et A4
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4, type="const")
A1stand<-rbind(summary(modele$varresult$MSESta)$coefficients[1:4,2], 
          summary(modele$varresult$PIBSta)$coefficients[1:4,2], 
          summary(modele$varresult$SMICSta)$coefficients[1:4,2],
          summary(modele$varresult$TCHOFSta)$coefficients[1:4,2])
colnames(A1stand)<-rownames(A1stand)<-c("MSE", "PIB", "SMIC", "TCHOF")
A2stand<-rbind(summary(modele$varresult$MSESta)$coefficients[5:8,2], 
          summary(modele$varresult$PIBSta)$coefficients[5:8,2], 
          summary(modele$varresult$SMICSta)$coefficients[5:8,2],
          summary(modele$varresult$TCHOFSta)$coefficients[5:8,2])
colnames(A2stand)<-rownames(A2stand)<-c("MSE", "PIB", "SMIC", "TCHOF")
A2
A3stand<-rbind(summary(modele$varresult$MSESta)$coefficients[9:12,2],
          summary(modele$varresult$PIBSta)$coefficients[9:12,2],
          summary(modele$varresult$SMICSta)$coefficients[9:12,2],
          summary(modele$varresult$TCHOFSta)$coefficients[9:12,2])
colnames(A3stand)<-rownames(A3stand)<-c("MSE", "PIB", "SMIC", "TCHOF")
A3
A4stand<-rbind(summary(modele$varresult$MSESta)$coefficients[13:16,2],
          summary(modele$varresult$PIBSta)$coefficients[13:16,2],
          summary(modele$varresult$SMICSta)$coefficients[13:16,2],
          summary(modele$varresult$TCHOFSta)$coefficients[13:16,2])
colnames(A4stand)<-rownames(A4stand)<-c("MSE", "PIB", "SMIC", "TCHOF")
A4

A0stand<-c(summary(modele$varresult$MSESta)$coefficients[17,2], 
          summary(modele$varresult$PIBSta)$coefficients[17,2], 
          summary(modele$varresult$SMICSta)$coefficients[17,2],
          summary(modele$varresult$TCHOFSta)$coefficients[17,2])
names(A0stand)<-c("MSE", "PIB", "SMIC", "TCHOF")
```

#Annexe 4 : Résultats obtenus pour un modèle VAR d'ordre 3 pour le modèle complet avec le package MTS \label{Annexe4}
```{r, echo=F}
require(MTS)
VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3)
```

#Annexe 5 : Résultats obtenus pour un modèle VAR d'ordre 2 pour le modèle complet avec le package MTS \label{Annexe5}
```{r, echo=F}
VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=2)
```

#Annexe 6 : Résultats obtenus pour un modèle VARMA(3,1) pour le modèle complet \label{Annexe6}
```{r, echo=F}
VARMA(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3, q=1)
```

#Annexe 7 : Code R du projet

```{r, eval=F}

####################### Fonctions créées pour optimiser le traitement ######################

EQM<-function(serie, prediction){
  return(sum((serie - prediction)^2)/length(serie))
}

stabilityvars<-function(modele){
  k<-modele$K
  p<-modele$p
  A <- matrix(0,nrow=p*k, ncol=p*k)
  deb<-nrow(A)-k+1
  for(i in seq(1,(nrow(A)-2*k+1),k)){
    A[(i+k):(i+k*2-1),i:(i+k-1)] = diag(k)
  }
  for(i in seq(1,deb,k)){
    A[1:k,i:(i+k-1)] = getCoefMatrix(modele, i)
  }
  vp<-eigen(A)$values
  print(Mod(vp))
  plot(seq(1,nrow(A)), Mod(vp), xlab="",
       ylab="Modules des valeurs propres", ylim=c(0,1.5))
  abline(h=1, col="red")
}

getCoefMatrix<-function(modele, p){
  k<-modele$K
  result<-matrix(nrow=k, ncol=k)
  for(i in 1:length(modele$varresult)){
    result[i,] = modele$varresult[[i]]$coefficients[1:(1+k-1)]
  }
  return(result)
}

stabilityMTS<-function(modele){
  k<-ncol(modele$data)
  p<-modele$order
  A <- matrix(0,nrow=p*k, ncol=p*k)
  deb<-nrow(A)-k+1
  for(i in seq(1,(nrow(A)-2*k+1),k)){
    A[i:(i+k-1),(i+k):(i+k*2-1)] = diag(k)
  }
  j = ncol(A)
  for(i in seq(1,deb,k)){
    A[deb:nrow(A),(j-k+1):j] = t(modele$coef[(i+1):(i+k),])
    j = j-k
  }
  vp<-eigen(A)$values
  print(Mod(vp))
  plot(seq(1,nrow(A)), Mod(vp), xlab="",
       ylab="Modules des valeurs propres", ylim=c(0,1.5))
  abline(h=1, col="red")
}

cor.mtest <- function(mat, conf.level = 0.95){
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  diag(lowCI.mat) <- diag(uppCI.mat) <- 1
  for(i in 1:(n-1)){
    for(j in (i+1):n){
      tmp <- cor.test(mat[,i], mat[,j], conf.level = conf.level)
      p.mat[i,j] <- p.mat[j,i] <- tmp$p.value
      lowCI.mat[i,j] <- lowCI.mat[j,i] <- tmp$conf.int[1]
      uppCI.mat[i,j] <- uppCI.mat[j,i] <- tmp$conf.int[2]
    }
  }
  return(list(p.mat, lowCI.mat, uppCI.mat))
}

archTest<-function(modele){
  a1 <- c()
  for(i in 1:18){
    a1[i] <- arch.test(modele, lags.multi = i)$arch.mul$p.value
  }
  plot(a1, type="l", main="Evolution de la p-value en fonction du lag", xlab="lag", ylab="p-value")
  abline(h=0.05, col="red")
}

calculC0<-function(modele){
  C0 <- matrix(nrow = modele$K, ncol=modele$K, 0)
  for(i in 1:nrow(residuals(modele))){
    C0 <- C0 + residuals(modele)[i,]%*%t(residuals(modele)[i,])
  }
  C0 <- (1/nrow(residuals(modele))) * C0
  C0
  d <- det(C0)
  names(d) <- "Déterminant de la matrice"
  d
}
###########################################################################################

########################### Importation des données  ######################################
trim <- read.csv("~/PFE_Time_Series/Data/Data_Trim.csv", sep=";", dec=",")
###########################################################################################

########################### Analyse descriptive des séries ################################

#MSE
#Transformation de la masse salariale en série temporelle
MSE <- ts(trim$MSE, start = 1990, end = c(2017, 2), frequency=4)
#Affichage de la série temporelle
plot(MSE, main="Evolution trimestrielle de la masse salariale", xaxt="n", cex.main=0.9)
#Modification de l'axe x pour afficher le nom des trimestres
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2), cex.main=0.8)
#Calcul de l'ACF et des PACF de la masse salariale
acf(MSE, main="Auto-corrélation de la masse salariale trimestrielle", lag.max=20)
pacf(MSE, main="Autocorrélation partielle de la masse salariale trimestrielle", lag.max=20)
#Réalisation de tests de stationnarité et de racines unitaires
kpss.test(MSE)
adf.test(MSE)

#PIB
#Transformation du PIB en série temporelle
PIB <- ts(trim$PIB, start = 1990, end = c(2017, 1), frequency=4)
#Affichage du PIB
plot(PIB, main="Evolution trimestrielle du PIB", xaxt="n", cex.main=0.9)
#Modification de l'axe x
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2), cex.main=0.8)
#Calcul de l'ACF et la PACF du PIB
acf(PIB, main="Auto-corrélation du PIB trimestriel", lag.max=40)
pacf(PIB, main="Autocorrélation partielle du PIB trimestriel", lag.max=40)
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(PIB)
adf.test(PIB)

#SMIC
#Transformation du SMIC en série temporelle
SMIC <- ts(trim$SMIC, start = c(1990,1), end = c(2017, 4), frequency = 4)
#Affichage du SMIC
plot(SMIC, main="Evolution trimestrielle du SMIC", xaxt="n", cex.main=0.9)
#Modification de l'axe x
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2), cex.main=0.8)
#Calcul de l'ACF et la PACF du SMIC
acf(SMIC, main="Auto-corrélation du SMIC trimestriel", lag.max=20)
pacf(SMIC, main="Autocorrélation partielle du SMIC trimestriel", lag.max=20)
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(SMIC)
adf.test(SMIC)

#TCHOF
#Création du taux de chômage en série temporelle
TCHOF <- ts(trim$TCHOF, start = c(1990,1), end = c(2017, 4), frequency = 4)
#Affichage du taux de chômage
plot(TCHOF, main="Evolution trimestrielle du taux de chômage des femmes", xaxt="n", cex.main=0.9)
#Modification de l'axe x
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2), cex.main=0.8)
#Calcul de l'ACF et de la PACF du taux de chômage
acf(TCHOF, main="Auto-corrélation du taux de chômage des femmes trimestriel", lag.max=20)
pacf(TCHOF, main="Autocorrélation partielle du taux de chômage des femmes trimestriel", lag.max=20)
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(TCHOF)
adf.test(TCHOF)

#Corrélations

#Matrice des corrélations
corrplot(cor(trim[1:109,-1]), method = "number", type="lower",
         p.mat=cor.mtest(trim[1:109,-1], 0.95)[[1]], insig="pch",
         col=colorRampPalette(c("blue", "light blue", "red"))(50))
#Calcul des p-values associées aux coefficients
corr <- cor.mtest(trim[1:109,-1], 0.95)[[1]]
#Ajout des libellés à la matrice des p-values
rownames(corr) <- c("MSE","PIB","SMIC","TCHOF")
colnames(corr) <- c("MSE","PIB","SMIC","TCHOF")
#Affichage des p-values
corr

#Découpage des séries en échantillons d'apprentissage et de test
MSETrain <- window(MSE, start=1990, end=c(2015,4))
MSETest <- window(MSE, start=2016, end=c(2017,2))
PIBTrain <- window(PIB, start=1990, end=c(2015,4))
PIBTest <- window(PIB, start=2016, end=c(2017,1))
SMICTrain <- window(SMIC, start=1990, end=c(2015,4))
SMICTest <- window(SMIC, start=2016, end=c(2017,2))
TCHOFTrain <- window(TCHOF, start=1990, end=c(2015,4))
TCHOFTest <- window(TCHOF, start=2016, end=c(2017,2))

###########################################################################################

############################## Modélisation individuelle ##################################

##Lissage exponentiel

#MSE
#Création du lissage exponentiel de la masse salariale
LEMSE<-ets(MSETrain, "ZAM")
#Affichage des différents coefficients du lissage
print(LEMSE)
#Prédiction des 6 prochaines valeurs
PredLEMSE <- forecast(LEMSE, h = 6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(MSETest, main="Comparaison entre la prédiction du lissage exponentiel et les valeurs réelles pour la masse salariale trimestrielle")
lines(PredLEMSE$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(MSETest, PredLEMSE$mean)

#PIB
#Création du lissage exponentiel du PIB
LEPIB<-ets(PIBTrain, "ZAN")
#Affichage des différents coefficients du lissage
print(LEPIB)
#Prédiction des 5 prochaines valeurs
PredLEPIB <- forecast(LEPIB, h = 5)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PIBTest, ylim=c(min(PIBTest,PredLEPIB$mean),max(PIBTest,PredLEPIB$mean)), main= "Comparaison entre la prédiction du lissage exponentiel et les valeurs réelles pour le PIB trimestriel", cex.main=0.8)
lines(PredLEPIB$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PIBTest, PredLEPIB$mean)

#SMIC
#Création du lissage exponentiel du SMIC
LESMIC<-ets(SMICTrain, "ZAA")
#Affichage des différents coefficients du lissage
print(LESMIC)
#Prédiction des 6 prochaines valeurs
PredLESMIC <- forecast(LESMIC, h = 6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(SMICTest, ylim=c(min(SMICTest,PredLESMIC$mean),max(SMICTest,PredLESMIC$mean)), main="Comparaison entre la prédiction du lissage exponentiel et les valeurs réelles pour le SMIC trimestriel", cex.main=0.8)
lines(PredLESMIC$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(SMICTest, PredLESMIC$mean)

#Taux de chômage des femmes
#Création du lissage exponentiel du taux de chômage
LETCHOF<-ets(TCHOFTrain, "ZNN")
#Affichage des différents coefficients
print(LETCHOF)
#Prédiction des 6 prochaines valeurs
PredLETCHOF <- forecast(LETCHOF, h = 6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(TCHOFTest, ylim=c(min(TCHOFTest,PredLETCHOF$mean),max(TCHOFTest,PredLETCHOF$mean)), main="Comparaison entre la prédiction du lissage exponentiel et les valeurs réelles pour le taux de chômage trimestriel", cex.main=0.8)
lines(PredLETCHOF$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(TCHOFTest, PredLETCHOF$mean)

#Modèles ARMA

#MSE
#Création du modèle SARIMA de la masse salariale
ARIMAMSE<-auto.arima(MSETrain, ic="aicc")
#Affichage des ordres et des coefficients du modèle
print(ARIMAMSE)
#Prédiction des 6 prochaines valeurs
PredARIMAMSE<- forecast(ARIMAMSE, h=6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(MSETest, main="Comparaison entre le modèle SARIMA et les données de validation pour la masse salariale trimestrielle")
lines(PredARIMAMSE$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(MSETest, PredARIMAMSE$mean)

#PIB
#Création du modèle ARIMA du PIB
ARIMAPIB<-auto.arima(PIBTrain, ic="aicc", seasonal=F)
#Affichage des ordres et des coefficients du modèle
print(ARIMAPIB)
#Prédiction des 5 prochaines valeurs
PredARIMAPIB<- forecast(ARIMAPIB, h=5)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PIBTest, ylim=c(min(PIBTest,PredARIMAPIB$mean),max(PIBTest,PredARIMAPIB$mean)), 
     main="Comparaison entre le modèle SARIMA et les données de
     validation pour le PIB trimestriel", cex.main=0.8)
lines(PredARIMAPIB$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PIBTest, PredARIMAPIB$mean)

#SMIC
#Création du modèle SARIMA du SMIC
ARIMASMIC<-auto.arima(SMICTrain, ic="aicc")
#Affichage des ordres et des coefficients du modèle
print(ARIMASMIC)
#Prédiction des 6 prochaines valeurs
PredARIMASMIC<- forecast(ARIMASMIC, h=6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(SMICTest, ylim=c(min(SMICTest,PredARIMASMIC$mean),max(SMICTest,PredARIMASMIC$mean)), 
     main="Comparaison entre le modèle SARIMA et les données de
    validation pour le SMIC trimestriel", cex.main=0.8)
lines(PredARIMASMIC$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(SMICTest, PredARIMASMIC$mean)

#TCHOF
#Création du modèle ARIMA du taux de chômage
ARIMATCHOF<-auto.arima(TCHOFTrain, ic="aicc", seasonal=F)
#Affichage des ordres et des coefficients du modèle
print(ARIMATCHOF)
#Prédiction des 6 prochaines valeurs
PredARIMATCHOF<- forecast(ARIMATCHOF, h=6)
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(TCHOFTest, main="Comparaison entre le modèle SARIMA et les données de
    validation pour le taux de chômage des femmes trimestriel", cex.main=0.8)
lines(PredARIMATCHOF$mean, col="red")
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(TCHOFTest, PredARIMATCHOF$mean)

#Comparaison des résultats
#Création d'une matrice stockant dans une colonne les EQM des prédiction des lissages et dans l'autre les
#prédictions des SARIMA
resultats<-matrix(nrow=4, ncol=2, dimnames = list(c("MSE", "PIB", "SMIC", "TCHOF"), 
                                                  c("lissage", "ARMA")))
#Remplissage de la matrice
resultats[1,1] = EQM(MSETest, PredLEMSE$mean)
resultats[2,1] = EQM(PIBTest, PredLEPIB$mean)
resultats[3,1] = EQM(SMICTest, PredLESMIC$mean)
resultats[4,1] = EQM(TCHOFTest, PredLETCHOF$mean)
resultats[1,2] = EQM(MSETest, PredARIMAMSE$mean)
resultats[2,2] = EQM(PIBTest, PredARIMAPIB$mean)
resultats[3,2] = EQM(SMICTest, PredARIMASMIC$mean)
resultats[4,2] = EQM(TCHOFTest, PredARIMATCHOF$mean)
#Affichage de la matrice
resultats

#Prédiction de la valeur du PIB pour 2017Q2
#Prédiction de la valeur manquante du PIB
PredARIMAPIB<- forecast(ARIMAPIB, h=6)
#Stockage de la valeur en question
new.value <- PredARIMAPIB$mean[6]
#Création du nouveau jeu de test du PIB avec la valeur estimée
PIBTest<-ts(c(PredARIMAPIB$mean, new.value), start = 2016, end = c(2017, 2), frequency=4)

###########################################################################################

##################### Modélisation ARMA avec variables exogènes de la MSE #################

#PIB
#Création d'un SARIMA du la masse salariale prenant en compte le PIB
SARIMAPIB <- auto.arima(MSETrain, xreg = cbind(PIBTrain))
SARIMAPIB
#Prédiction des prochaines valeurs
PredPIB <- forecast(SARIMAPIB, xreg = cbind(PIBTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredPIB$mean, col="red",
     ylim=c(min(MSETest,PredPIB$mean), max(MSETest,PredPIB$mean)),
     main = "Masse salariale expliquée par le PIB vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredPIB$mean, MSETest)

#SMIC
#Création d'un SARIMA du la masse salariale prenant en compte le SMIC
SARIMASMIC <- auto.arima(MSETrain, xreg = cbind(SMICTrain))
SARIMASMIC
#Prédiction des prochaines valeurs
PredSMIC <- forecast(SARIMASMIC, xreg = cbind(SMICTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredSMIC$mean, col="red",
     ylim=c(min(MSETest,PredSMIC$mean), max(MSETest,PredSMIC$mean)),
     main = "Masse salariale expliqué par le SMIC vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredSMIC$mean, MSETest)

#TCHOF
#Création d'un SARIMA du la masse salariale prenant en compte le taux de chômage
SARIMATCHOF <- auto.arima(MSETrain, xreg = cbind(TCHOFTrain))
SARIMATCHOF
#Prédiction des prochaines valeurs
PredTCHOF <- forecast(SARIMATCHOF, xreg = cbind(TCHOFTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredTCHOF$mean, col="red",
     ylim=c(min(MSETest,PredTCHOF$mean), max(MSETest,PredTCHOF$mean)),
     main = "Masse salariale expliquée par le taux de chômage vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredTCHOF$mean, MSETest)

#PIB & SMIC
#Création d'un SARIMA du la masse salariale prenant en compte le PIB et le SMIC
SARIMAPIBSMIC <- auto.arima(MSETrain, xreg = cbind(PIBTrain, SMICTrain))
SARIMAPIBSMIC
#Prédiction des prochaines valeurs
PredPIBSMIC <- forecast(SARIMAPIBSMIC, xreg = cbind(PIBTest, SMICTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredPIBSMIC$mean, col="red",
     ylim=c(min(MSETest,PredPIBSMIC$mean), max(MSETest,PredPIBSMIC$mean)),
     main = "Masse salariale expliquée par le PIB et le SMIC vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredPIBSMIC$mean, MSETest)

#PIB & TCHOF
#Création d'un SARIMA du la masse salariale prenant en compte le PIB et le taux de chômage
SARIMAPIBTCHOF <- auto.arima(MSETrain, xreg = cbind(PIBTrain, TCHOFTrain))
SARIMAPIBTCHOF
#Prédiction des prochaines valeurs
PredPIBTCHOF <- forecast(SARIMAPIBTCHOF, xreg = cbind(PIBTest, TCHOFTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredPIBTCHOF$mean, col="red",
     ylim=c(min(MSETest,PredPIBTCHOF$mean), max(MSETest,PredPIBTCHOF$mean)),
     main = "Masse salariale expliquée par le PIB et le taux de chômage vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredPIBTCHOF$mean, MSETest)

#SMIC & TCHOF
#Création d'un SARIMA du la masse salariale prenant en compte le SMIC et le taux de chômage
SARIMASMICTCHOF <- auto.arima(MSETrain, xreg = cbind(SMICTrain, TCHOFTrain))
SARIMASMICTCHOF
#Prédiction des prochaines valeurs
PredSMICTCHOF <- forecast(SARIMASMICTCHOF, xreg = cbind(SMICTest, TCHOFTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredSMICTCHOF$mean, col="red",
     ylim=c(min(MSETest,PredSMICTCHOF$mean), max(MSETest,PredSMICTCHOF$mean)),
     main = "Masse salariale expliquée par le SMIC et le taux de chômage vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredSMICTCHOF$mean, MSETest)

#PIB, SMIC & TCHOF
#Création d'un SARIMA du la masse salariale prenant en compte toutes les variables exogènes
SARIMACOMPLET <- auto.arima(MSETrain, xreg = cbind(PIBTrain, SMICTrain, TCHOFTrain))
SARIMACOMPLET
#Prédiction des prochaines valeurs
PredCOMPLET <- forecast(SARIMACOMPLET, xreg = cbind(PIBTest, SMICTest, TCHOFTest))
#Affichage de l'échantillon de test et des prédictions afin de les comparer
plot(PredCOMPLET$mean, col="red",
     ylim=c(min(MSETest,PredCOMPLET$mean), max(MSETest,PredCOMPLET$mean)),
     main = "Masse salariale expliquée par le PIB, le SMIC et le taux de chômage vs Vraies valeurs")
lines(MSETest)
#Calcul de l'EQM entre les prédictions et les valeurs de l'échantillon de test
EQM(PredCOMPLET$mean, MSETest)

#Comparaison des résultats
#Création d'un tableau stockant les EQM des différents modèles
resultats<-matrix(nrow=7, ncol=1, dimnames = list(c("PIB", "SMIC", "TCHOF", "PIB & SMIC", "PIB & SMIC", "PIB & TCHOF", "PIB, SMIC & TCHOF"), 
                                                  c("EQM")))
#Remplissage du tableau
resultats[1,1] = EQM(MSETest, PredPIB$mean)
resultats[2,1] = EQM(MSETest, PredSMIC$mean)
resultats[3,1] = EQM(MSETest, PredTCHOF$mean)
resultats[4,1] = EQM(MSETest, PredPIBSMIC$mean)
resultats[5,1] = EQM(MSETest, PredPIBTCHOF$mean)
resultats[6,1] = EQM(MSETest, PredSMICTCHOF$mean)
resultats[7,1] = EQM(MSETest, PredCOMPLET$mean)
resultats

###########################################################################################

############################### Stationnarisation des séries ##############################

#MSE
par(cex.main=0.8)
#Affichage de la décomposition de la masse salariale
plot(decompose(MSETrain, "multiplicative"))
#Stockage des différentes composantes de la masse salariale
MSESta <- na.omit(decompose(MSETrain, "multiplicative")$random)
MSETrend<-window(decompose(MSETrain, "multiplicative")$trend)
MSESeasonal<-window(decompose(MSETrain, "multiplicative")$seasonal)
#Affichage des résidus de la masse salariale
plot(MSESta, main="Masse salariale trimestrielle stationnarisée", xaxt="n")
#Modification de l'axe x
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2), cex.main=0.8)
#Calcul de l'ACF et la PACF de la masse salariale stationnarisée
acf(MSESta, main="ACF de la masse salariale stationnarisée")
pacf(MSESta, main="PACF de la masse salariale stationnarisée")
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(MSESta)
adf.test(MSESta)
#Création de vecteurs contenant la tendance et la saisonnalité des futures valeurs
MSETrendTest <- window(forecast(na.omit(MSETrend), h=8)$mean, start=2016)
MSESeasonalTest<-ts(c(MSESeasonal[1:4],MSESeasonal[1:2]), start=2016,frequency=4)

#PIB
#Stockage de la composante résiduelle du PIB
PIBSta <- na.omit(decompose(PIBTrain, "multiplicative")$random)
#Affichage des résidus du PIB
plot(PIBSta, main="PIB trimestriel stationnarisé", xaxt="n")
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2))
#Calcul de l'ACF et la PACF du PIB stationnarisée
acf(PIBSta, main="Auto-Corrélation du PIB trimestriel stationnarisé")
pacf(PIBSta, main="Auto-Corrélation partielle du PIB trimestriel stationnarisé")
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(PIBSta)
adf.test(PIBSta)

#SMIC
#Stockage de la composante résiduelle du SMIC
SMICSta <- na.omit(decompose(SMICTrain)$random)
#Affichage des résidus du SMIC
plot(SMICSta, main="SMIC trimestriel stationnarisé", xaxt="n")
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2))
#Calcul de l'ACF et la PACF du SMIC stationnarisée
acf(SMICSta, main="Auto-Corrélation du SMIC trimestriellstationnarisé")
pacf(SMICSta, main="Auto-Corrélation partielle du SMIC trimestriel stationnarisé")
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(SMICSta)
adf.test(SMICSta)

#TCHOF
#Stockage de la composante résiduelle du taux de chômage
TCHOFSta <- na.omit(decompose(TCHOFTrain)$random)
#Affichage des résidus du taux de chômage
plot(TCHOFSta, main="Taux de chômage trimestriel des femmes stationnarisé", xaxt="n")
axis(side=1, at=seq(1990,2015,5), labels=c("1990Q1", "1995Q1", "2000Q1", "2005Q1", "2010Q1", "2015Q1"))
#Division de l'espace d'affichage des graphiques en deux
par(mfrow=c(1,2))
#Calcul de l'ACF et la PACF du taux de chômage stationnarisée
acf(TCHOFSta, main="Auto-Corrélation du Taux de chômage des femmes trimestrielle stationnarisé")
pacf(TCHOFSta, main="Auto-Corrélation partielle du Taux de chômage des femmes trimestriel stationnarisé")
par(mfrow=c(1,1))
#Réalisation des tests de stationnarité et de racines unitaires
kpss.test(TCHOFSta)
adf.test(TCHOFSta)

###########################################################################################

################################## Modèles VAR avec vars ##################################
detach("package:MTS", unload=TRUE)

#PIB
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, PIBSta), lag.max=10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale et le PIB
modele<-VAR(cbind(MSESta, PIBSta), p=4, type="const")
#vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Ordre3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le PIB
modele2<-VAR(cbind(MSESta, PIBSta), p=3, type="const")
#vérification de la stabilité du modèle
stabilityvars(modele2)
#Test d'homoscédasticité
archTest(modele2)
#Test de normalité
normality.test(modele2)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele2)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele2)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec la masse salariale et le PIB
modele3<-VAR(cbind(MSESta, PIBSta), p=2, type="const")
#vérification de la stabilité du modèle
stabilityvars(modele3)
#Test d'homoscédasticité
archTest(modele3)
#Test de normalité
normality.test(modele3)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele3)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele3)

#Prédictions avec le modèle d'ordre 4 et calcul de l'EQM
PredPIB<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIB*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
#Prédictions avec le modèle d'ordre 3 et calcul de l'EQM
PredPIB2<-forecast(modele2, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIB2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
#Prédictions avec le modèle d'ordre 2 et calcul de l'EQM
PredPIB3<-forecast(modele3, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIB3*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIB, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#SMIC
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, SMICSta), lag.max=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le SMIC
modele<-VAR(cbind(MSESta, SMICSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Prédictions
PredSMIC<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredCOMPLET*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredSMIC, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, TCHOFSta), lag.max=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le taux de chômage
modele<-VAR(cbind(MSESta, TCHOFSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec la masse salariale et le taux de chômage
modele2<-VAR(cbind(MSESta, PIBSta), p=2, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele2)
#Test d'homoscédasticité
archTest(modele2)
#Test de normalité
normality.test(modele2)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele2)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele2)

#Prédictions avec le modèle d'ordre 3 et calcul de l'EQM
PredTCHOF<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
#Prédictions avec le modèle d'ordre 2 et calcul de l'EQM
PredTCHOF2<-forecast(modele2, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredTCHOF, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#PIB & SMIC
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, PIBSta, SMICSta), lag.max=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale, le PIB et le SMIC
modele<-VAR(cbind(MSESta, PIBSta, SMICSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Prédictions
PredPIBSMIC<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIBSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIBSMIC, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#PIB & TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, PIBSta, TCHOFSta), lag.max=10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale et le taux de chômage et le PIB
modele<-VAR(cbind(MSESta, PIBSta, TCHOFSta), p=4, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Ordre3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le taux de chômage et le PIB
modele2<-VAR(cbind(MSESta, PIBSta, TCHOFSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele2)
#Test d'homoscédasticité
archTest(modele2)
#Test de normalité
normality.test(modele2)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele2)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele2)

#Prédictions
PredPIBTCHOF<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIBTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredPIBTCHOF2<-forecast(modele2, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredPIBTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIBTCHOF, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#SMIC & TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, SMICSta, TCHOFSta), lag.max=10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale et le taux de chômage et le SMIC
modele<-VAR(cbind(MSESta, SMICSta, TCHOFSta), p=4, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Ordre3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le taux de chômage et le SMIC
modele2<-VAR(cbind(MSESta, SMICSta, TCHOFSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele2)
#Test d'homoscédasticité
archTest(modele2)
#Test de normalité
normality.test(modele2)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele2)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele2)

#Prédictions
PredSMICTCHOF<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredSMICTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredSMICTCHOF2<-forecast(modele2, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredSMICTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredSMICTCHOF, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#Modèle complet
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARselect(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), lag.max=10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec toutes les variables
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele)
#Test d'homoscédasticité
archTest(modele)
#Test de normalité
normality.test(modele)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele)

#Ordre3
#Réalisation d'un modèle d'ordre 3 avec toutes les variables
modele2<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele2)
#Test d'homoscédasticité
archTest(modele2)
#Test de normalité
normality.test(modele2)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele2)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele2)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec toutes les variables
modele3<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=2, type="const")
#Vérification de la stabilité du modèle
stabilityvars(modele3)
#Test d'homoscédasticité
archTest(modele3)
#Test de normalité
normality.test(modele3)$jb.mul$JB
#Vérification de l'inversibilité de la matrice
calculC0(modele3)
#Test d'auto-corrélation et de corrélation croisée
Portmanteau(modele3)

#Prédictions
PredCOMPLET<-forecast(modele, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredCOMPLET*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredCOMPLET2<-forecast(modele2, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredCOMPLET2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredCOMPLET3<-forecast(modele3, h=8)$forecast$MSESta$mean
EQM(MSETest, window(PredCOMPLET3*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredCOMPLET, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#Comparaison des résultats
resultats<-matrix(nrow=7, ncol=1, dimnames = list(c("PIB", "SMIC", "TCHOF", "PIB & SMIC", "PIB & TCHOF", "SMIC & TCHOF", "PIB, SMIC & TCHOF"), 
                                                  c("EQM")))
resultats[1,1] = EQM(MSETest, window(PredPIB*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[2,1] = EQM(MSETest, window(PredSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[3,1] = EQM(MSETest, window(PredTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[4,1] = EQM(MSETest, window(PredPIBSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[5,1] = EQM(MSETest, window(PredPIBTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[6,1] = EQM(MSETest, window(PredSMICTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[7,1] = EQM(MSETest, window(PredCOMPLET*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats

###########################################################################################

################################### Modèles VAR avec MTS ##################################

require(MTS)

#PIB
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, PIBSta), maxp = 10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale et le PIB
modele<-VAR(cbind(MSESta, PIBSta), p=4)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le PIB
modele2<-VAR(cbind(MSESta, PIBSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele2)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele2)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Prédictions
PredPIB<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIB*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredPIB2<-window(ts(VARpred(modele2, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIB2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIB, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#SMIC
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, SMICSta), maxp = 10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le SMIC
modele<-VAR(cbind(MSESta, SMICSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Prédictions
PredSMIC<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIB, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, TCHOFSta), maxp = 10)

#Ordre 6
#Réalisation d'un modèle d'ordre 6 avec la masse salariale et le taux de chômage
modele<-VAR(cbind(MSESta, TCHOFSta), p=6)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale et le taux de chômage
modele2<-VAR(cbind(MSESta, TCHOFSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele2)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele2)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec la masse salariale et le taux de chômage
modele3<-VAR(cbind(MSESta, TCHOFSta), p=2)
#Vérification de la stabilité du modèle
stabilityMTS(modele3)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele3)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Prédictions
PredTCHOF<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredTCHOF2<-window(ts(VARpred(modele2, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredTCHOF3<-window(ts(VARpred(modele3, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredTCHOF3*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredTCHOF, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#PIB & SMIC
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, PIBSta, SMICSta), maxp = 10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale, le PIB et le SMIC
modele<-VAR(cbind(MSESta, PIBSta, SMICSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Prédictions
PredPIBSMIC<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIBSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIBSMIC, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#PIB & TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, PIBSta, TCHOFSta), maxp = 10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale, le PIB et le taux de chômage
modele<-VAR(cbind(MSESta, PIBSta, TCHOFSta), p=4)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale, le PIB et le taux de chômage
modele2<-VAR(cbind(MSESta, PIBSta, TCHOFSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele2)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele2)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec la masse salariale, le PIB et le taux de chômage
modele3<-VAR(cbind(MSESta, PIBSta, TCHOFSta), p=2)
#Vérification de la stabilité du modèle
stabilityMTS(modele3)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele3)
#test du Portmanteau
mq(modele3$residuals, lag=10)

#Prédictions
PredPIBTCHOF<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIBTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredPIBTCHOF2<-window(ts(VARpred(modele2, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIBTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredPIBTCHOF3<-window(ts(VARpred(modele3, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredPIBTCHOF3*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredPIB, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#SMIC & TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, SMICSta, TCHOFSta), maxp = 10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec la masse salariale, le SMIC et le taux de chômage
modele<-VAR(cbind(MSESta, SMICSta, TCHOFSta), p=4)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec la masse salariale, le SMIC et le taux de chômage
modele2<-VAR(cbind(MSESta, SMICSta, TCHOFSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele2)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele2)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Prédictions
PredSMICTCHOF<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredSMICTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredSMICTCHOF2<-window(ts(VARpred(modele2, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredSMICTCHOF2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredSMICTCHOF, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#PIB, SMIC & TCHOF
#Selection de l'ordre du modèle VAR en fonction de différents critères
VARorder(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), maxp = 10)

#Ordre 4
#Réalisation d'un modèle d'ordre 4 avec toutes les variables
modele<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=4)
#Vérification de la stabilité du modèle
stabilityMTS(modele)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele)
#test du Portmanteau
mq(modele$residuals, lag=10)

#Ordre 3
#Réalisation d'un modèle d'ordre 3 avec toutes les variables
modele2<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3)
#Vérification de la stabilité du modèle
stabilityMTS(modele2)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele2)
#test du Portmanteau
mq(modele2$residuals, lag=10)

#Ordre 2
#Réalisation d'un modèle d'ordre 2 avec toutes les variables
modele3<-VAR(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=2)
#Vérification de la stabilité du modèle
stabilityMTS(modele3)
#Test d'auto-corrélation et de corrélation croisée
crossCorr(modele3)
#test du Portmanteau
mq(modele3$residuals, lag=10)

#Prédictions
PredCOMPLET<-window(ts(VARpred(modele, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredCOMPLET*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredCOMPLET2<-window(ts(VARpred(modele2, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredCOMPLET2*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
PredCOMPLET3<-window(ts(VARpred(modele3, 8)$pred[,1], start=c(2015,3), frequency=4), start=2016)
EQM(MSETest, window(PredCOMPLET3*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))

#Affichage des valeurs de l'échantillon de test et comparaison avec les prédictions
plot(MSETest, xlim=c(2016,2017.25), main="Différences entre les véritables
     valeurs et les prédictions du modèle pour la masse salariale", xaxt="n")
axis(side=1, at=seq(2016,2017.25,0.25), labels=c("2016Q1", "2016Q2", "2016Q3", "2016Q4", "2017Q1", "2017Q2"))
lines(window(PredCOMPLET, start=2016, end=c(2017,2))*MSETrendTest*MSESeasonalTest, col = "red")

#Comparaison des résultats
resultats<-matrix(nrow=7, ncol=1, dimnames = list(c("PIB", "SMIC", "TCHOF", "PIB & SMIC", "PIB & TCHOF", "SMIC & TCHOF", "PIB, SMIC & TCHOF"), c("EQM")))
resultats[1,1] = EQM(MSETest, window(PredPIB*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[2,1] = EQM(MSETest, window(PredSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[3,1] = EQM(MSETest, window(PredTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[4,1] = EQM(MSETest, window(PredPIBSMIC*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[5,1] = EQM(MSETest, window(PredPIBTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[6,1] = EQM(MSETest, window(PredSMICTCHOF*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats[7,1] = EQM(MSETest, window(PredCOMPLET*MSETrendTest*MSESeasonalTest, start=2016, end=c(2017,2)))
resultats

###########################################################################################

################################# Modèles VARMA avec MTS #################################

#Estimation de l'ordre du modèle
Eccm(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), maxq=5)
#Réalisation d'un modèle d'ordre p=3 et q=1 avec toutes les variables
modele<-VARMA(cbind(MSESta, PIBSta, SMICSta, TCHOFSta), p=3, q=1)
#Elimination des paramètres non significatifs du modèle
modele<-refVARMA(modele)

###########################################################################################
```

\newpage

#References {-}